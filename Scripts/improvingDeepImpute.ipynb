{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution based on... (DIMENSION TO DO CONVOLUTION ON) \n",
    "- Gene functionality (GO analysis) \n",
    "- Each convolutional layer is the top k genes correlated with the target genes (i.e. n_top = 5) \n",
    "- Random \n",
    "\n",
    "## Thungs to try instead of correlation\n",
    "- Euclidean distance in n-dim array \n",
    "- Manhattan distance (look into it?) \n",
    "- Root Mean Squared Error \n",
    "\n",
    "## Activation functions to test (if I understand this correctly)\n",
    "- ReLU (default) \n",
    "- Sigmoid (all positive, \"gradual\") \n",
    "- Softplus (gradual ReLU) \n",
    "\n",
    "## Loss function...\n",
    "\"The loss function to use during training is typically the mean squared error, but if you have a lot of outliers <br />\n",
    "in the training set, you may prefer to use the mean absolute error instead. Alternatively, you can use the Huber <br />\n",
    "loss, which is a combination of both.\"\n",
    "\n",
    "## Dropout layer \n",
    "- \"...closer to 20–30% in recurrent neural nets, and closer to 40–50% in convolutional neural networks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.losses\n",
    "from keras import backend as K\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\n",
    "    '/Volumes/Samsung_T5/ResearchData/scanpyTutorial/data/filtered_gene_bc_matrices/hg19',  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',                      # use gene symbols for the variable names (variables-axis index)\n",
    "    cache=True)\n",
    "\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Working on 2700 cells and 32738 genes\n"
    }
   ],
   "source": [
    "data = pd.DataFrame.sparse.from_spmatrix(adata.X)\n",
    "print('Working on {} cells and {} genes'.format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VMR = data.std() / data.mean()  # coefficient of variation: stdDev/mean (relative magnitude of std dev)\n",
    "VMR[np.isinf(VMR)] = 0  # if mean is 0, we would get an infinite value --> set it to zero\n",
    "potential_pred = data.columns[VMR > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(16634, 16634)"
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Create covariance matrix (pd data frame),\n",
    "covariance_matrix = pd.DataFrame(np.abs(np.corrcoef(data[potential_pred], rowvar= False)), # rowvar=False -> each column represents variable\n",
    "    index=potential_pred,\n",
    "    columns=potential_pred).fillna(0) # setting column names and fill NA with 0\n",
    "\n",
    "covariance_matrix.shape; max(pd.Series.max(covariance_matrix)); min(pd.Series.min(covariance_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pred_unnorm = data.loc[:,potential_pred] # UNNORMALIZED\n",
    "\n",
    "# gene_metric = (data_pred_unnorm.var()/(1+data_pred_unnorm.mean())).sort_values(ascending=False)\n",
    "# gene_metric = gene_metric[gene_metric > 0]\n",
    "\n",
    "# data_pred = np.log1p(data_pred_unnorm).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2700, 16634)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "data_pred_full = data.loc[:,potential_pred] # UNNORMALIZED\n",
    "\n",
    "gene_metric = (data_pred_full.var()/(1+data_pred_full.mean())).sort_values(ascending=False)\n",
    "gene_metric = gene_metric[gene_metric > 0]\n",
    "\n",
    "data_pred_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(270, 16634)"
     },
     "metadata": {},
     "execution_count": 27
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2430, 16634)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# separating 10% that will be untouched during cross-validation\n",
    "untouched_10_index = np.random.choice(data_pred_full.index, int(0.10 * data_pred_full.shape[0]), replace=False)\n",
    "untouched_10 = data_pred_full.loc[untouched_10_index,:]\n",
    "untouched_10.shape\n",
    "\n",
    "touched_90_index = np.setdiff1d(data_pred_full.index, untouched_10_index)\n",
    "data_pred = data_pred_full.loc[touched_90_index,:]\n",
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Working on Batch 1\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2430, 512)"
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2430, 16122)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Defining target variable (y = 512 genes, x = 1800 ish genes)\n",
    "batch = 1\n",
    "indx = range((512*(batch-1)),(512*batch))\n",
    "print('Working on Batch {}'.format(batch))\n",
    "\n",
    "target_index = gene_metric.index[indx]\n",
    "target = data_pred.loc[:,target_index]\n",
    "target.shape\n",
    "\n",
    "not_target_index = gene_metric.index[list(set(range(16634)) - set(indx))]\n",
    "not_target = data_pred.loc[:,not_target_index]\n",
    "not_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(512, 16122)"
     },
     "metadata": {},
     "execution_count": 29
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9896605340015643"
     },
     "metadata": {},
     "execution_count": 29
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "subMatrix = covariance_matrix.loc[target_index, not_target_index]\n",
    "subMatrix.shape; max(pd.Series.max(subMatrix)); min(pd.Series.min(subMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2430, 1425)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(512):\n",
    "    indx = pd.Series.nlargest(subMatrix.iloc[i,:], 5).index\n",
    "    x.extend(pd.Index.tolist(indx))\n",
    "predictor_index = set(x) #keep unique only\n",
    "predictor = data_pred.loc[:,predictor_index]\n",
    "predictor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2308, 1425) (2308, 512)\n(122, 1425) (122, 512)\n"
    }
   ],
   "source": [
    "# Normal way\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(predictor), np.asarray(target), test_size=0.05)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 256)               365056    \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               131584    \n=================================================================\nTotal params: 496,640\nTrainable params: 496,640\nNon-trainable params: 0\n_________________________________________________________________\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array([[-0.04244902, -0.05158878, -0.02538938, ...,  0.05638805,\n         -0.0009089 , -0.0028037 ],\n        [-0.03996004, -0.02327196,  0.00896781, ...,  0.03340445,\n          0.05302871,  0.03131932],\n        [ 0.04178888,  0.05362334,  0.05917939, ..., -0.01493469,\n          0.02819781,  0.00310026],\n        ...,\n        [ 0.03894501, -0.00390575,  0.0210615 , ...,  0.03662151,\n         -0.04158338, -0.02303334],\n        [ 0.01950132, -0.04641075, -0.0145807 , ..., -0.00769969,\n          0.00153995,  0.04622838],\n        [ 0.05273062,  0.0249234 ,  0.01818494, ...,  0.01158524,\n          0.01059407, -0.02490923]], dtype=float32),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0.], dtype=float32)]"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "model = Sequential([ \n",
    "    Input(shape=( predictor.shape[1] ,)), \n",
    "    Dense(units=256, activation=\"relu\"), \n",
    "    Dropout(rate=0.2),\n",
    "    Dense(units=512, activation=\"softplus\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.layers[0].get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/500\n41/41 [==============================] - 5s 133ms/step - loss: 1.8769 - accuracy: 0.0203 - val_loss: 1.7297 - val_accuracy: 0.0444\nEpoch 2/500\n41/41 [==============================] - 0s 4ms/step - loss: 1.2986 - accuracy: 0.0694 - val_loss: 0.8658 - val_accuracy: 0.1185\nEpoch 3/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.1057 - val_loss: 0.4995 - val_accuracy: 0.1259\nEpoch 4/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.1887 - val_loss: 0.4305 - val_accuracy: 0.2815\nEpoch 5/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.2694 - val_loss: 0.3915 - val_accuracy: 0.3630\nEpoch 6/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.2986 - val_loss: 0.3625 - val_accuracy: 0.4148\nEpoch 7/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.3201 - val_loss: 0.3405 - val_accuracy: 0.4519\nEpoch 8/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.3287 - val_loss: 0.3215 - val_accuracy: 0.4593\nEpoch 9/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.3583 - val_loss: 0.3065 - val_accuracy: 0.4963\nEpoch 10/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.3610 - val_loss: 0.2900 - val_accuracy: 0.4963\nEpoch 11/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.4062 - val_loss: 0.2804 - val_accuracy: 0.5111\nEpoch 12/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.4269 - val_loss: 0.2719 - val_accuracy: 0.5333\nEpoch 13/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.4468 - val_loss: 0.2634 - val_accuracy: 0.5556\nEpoch 14/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.4382 - val_loss: 0.2569 - val_accuracy: 0.5481\nEpoch 15/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.4519 - val_loss: 0.2523 - val_accuracy: 0.5778\nEpoch 16/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.4565 - val_loss: 0.2482 - val_accuracy: 0.5778\nEpoch 17/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.4639 - val_loss: 0.2433 - val_accuracy: 0.5926\nEpoch 18/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.4710 - val_loss: 0.2408 - val_accuracy: 0.5852\nEpoch 19/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.4752 - val_loss: 0.2375 - val_accuracy: 0.5704\nEpoch 20/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.4862 - val_loss: 0.2346 - val_accuracy: 0.5630\nEpoch 21/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.4908 - val_loss: 0.2323 - val_accuracy: 0.5704\nEpoch 22/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.2282 - accuracy: 0.4869 - val_loss: 0.2299 - val_accuracy: 0.5704\nEpoch 23/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.4928 - val_loss: 0.2279 - val_accuracy: 0.5556\nEpoch 24/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2230 - accuracy: 0.5045 - val_loss: 0.2269 - val_accuracy: 0.5630\nEpoch 25/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.5099 - val_loss: 0.2251 - val_accuracy: 0.5704\nEpoch 26/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.5080 - val_loss: 0.2245 - val_accuracy: 0.5704\nEpoch 27/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.5162 - val_loss: 0.2211 - val_accuracy: 0.5630\nEpoch 28/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.5041 - val_loss: 0.2200 - val_accuracy: 0.5630\nEpoch 29/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.5049 - val_loss: 0.2190 - val_accuracy: 0.5630\nEpoch 30/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2054 - accuracy: 0.5150 - val_loss: 0.2177 - val_accuracy: 0.5556\nEpoch 31/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.5232 - val_loss: 0.2159 - val_accuracy: 0.5630\nEpoch 32/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.5271 - val_loss: 0.2145 - val_accuracy: 0.5481\nEpoch 33/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.5189 - val_loss: 0.2129 - val_accuracy: 0.5556\nEpoch 34/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1968 - accuracy: 0.5162 - val_loss: 0.2119 - val_accuracy: 0.5481\nEpoch 35/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.5131 - val_loss: 0.2105 - val_accuracy: 0.5481\nEpoch 36/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.5224 - val_loss: 0.2093 - val_accuracy: 0.5630\nEpoch 37/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.5283 - val_loss: 0.2082 - val_accuracy: 0.5556\nEpoch 38/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.5314 - val_loss: 0.2077 - val_accuracy: 0.5630\nEpoch 39/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.5224 - val_loss: 0.2067 - val_accuracy: 0.5556\nEpoch 40/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.5322 - val_loss: 0.2053 - val_accuracy: 0.5556\nEpoch 41/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.5310 - val_loss: 0.2045 - val_accuracy: 0.5556\nEpoch 42/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.5318 - val_loss: 0.2038 - val_accuracy: 0.5556\nEpoch 43/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.5283 - val_loss: 0.2030 - val_accuracy: 0.5556\nEpoch 44/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.5388 - val_loss: 0.2021 - val_accuracy: 0.5556\nEpoch 45/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.5380 - val_loss: 0.2008 - val_accuracy: 0.5556\nEpoch 46/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.5404 - val_loss: 0.1995 - val_accuracy: 0.5556\nEpoch 47/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.5333 - val_loss: 0.1990 - val_accuracy: 0.5481\nEpoch 48/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.5411 - val_loss: 0.1981 - val_accuracy: 0.5556\nEpoch 49/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.5400 - val_loss: 0.1968 - val_accuracy: 0.5630\nEpoch 50/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.5427 - val_loss: 0.1964 - val_accuracy: 0.5630\nEpoch 51/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.5329 - val_loss: 0.1956 - val_accuracy: 0.5630\nEpoch 52/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.5392 - val_loss: 0.1953 - val_accuracy: 0.5630\nEpoch 53/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.5361 - val_loss: 0.1946 - val_accuracy: 0.5630\nEpoch 54/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.5458 - val_loss: 0.1933 - val_accuracy: 0.5630\nEpoch 55/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.5485 - val_loss: 0.1931 - val_accuracy: 0.5630\nEpoch 56/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.5392 - val_loss: 0.1919 - val_accuracy: 0.5630\nEpoch 57/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.5505 - val_loss: 0.1914 - val_accuracy: 0.5630\nEpoch 58/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.5552 - val_loss: 0.1902 - val_accuracy: 0.5630\nEpoch 59/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.5462 - val_loss: 0.1902 - val_accuracy: 0.5630\nEpoch 60/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.5536 - val_loss: 0.1900 - val_accuracy: 0.5630\nEpoch 61/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.5446 - val_loss: 0.1894 - val_accuracy: 0.5630\nEpoch 62/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.5470 - val_loss: 0.1886 - val_accuracy: 0.5630\nEpoch 63/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.5501 - val_loss: 0.1879 - val_accuracy: 0.5630\nEpoch 64/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1600 - accuracy: 0.5509 - val_loss: 0.1872 - val_accuracy: 0.5704\nEpoch 65/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.5462 - val_loss: 0.1871 - val_accuracy: 0.5704\nEpoch 66/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.5559 - val_loss: 0.1862 - val_accuracy: 0.5704\nEpoch 67/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.5462 - val_loss: 0.1862 - val_accuracy: 0.5630\nEpoch 68/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1582 - accuracy: 0.5641 - val_loss: 0.1851 - val_accuracy: 0.5704\nEpoch 69/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.5556 - val_loss: 0.1849 - val_accuracy: 0.5704\nEpoch 70/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.5579 - val_loss: 0.1846 - val_accuracy: 0.5704\nEpoch 71/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.5563 - val_loss: 0.1843 - val_accuracy: 0.5704\nEpoch 72/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.5563 - val_loss: 0.1848 - val_accuracy: 0.5704\nEpoch 73/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.5614 - val_loss: 0.1843 - val_accuracy: 0.5704\nEpoch 74/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.5680 - val_loss: 0.1830 - val_accuracy: 0.5704\nEpoch 75/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.5618 - val_loss: 0.1828 - val_accuracy: 0.5630\nEpoch 76/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.5552 - val_loss: 0.1824 - val_accuracy: 0.5778\nEpoch 77/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.5602 - val_loss: 0.1829 - val_accuracy: 0.5778\nEpoch 78/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.5708 - val_loss: 0.1841 - val_accuracy: 0.5704\nEpoch 79/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.5544 - val_loss: 0.1830 - val_accuracy: 0.5704\nEpoch 80/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.5540 - val_loss: 0.1827 - val_accuracy: 0.5704\nEpoch 81/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.5657 - val_loss: 0.1822 - val_accuracy: 0.5778\nEpoch 82/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.5661 - val_loss: 0.1818 - val_accuracy: 0.5704\nEpoch 83/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.5587 - val_loss: 0.1809 - val_accuracy: 0.5704\nEpoch 84/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.5610 - val_loss: 0.1807 - val_accuracy: 0.5704\nEpoch 85/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.5579 - val_loss: 0.1805 - val_accuracy: 0.5704\nEpoch 86/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.5626 - val_loss: 0.1805 - val_accuracy: 0.5704\nEpoch 87/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.5743 - val_loss: 0.1801 - val_accuracy: 0.5852\nEpoch 88/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.5673 - val_loss: 0.1807 - val_accuracy: 0.5704\nEpoch 89/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.5684 - val_loss: 0.1808 - val_accuracy: 0.5778\nEpoch 90/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.5708 - val_loss: 0.1805 - val_accuracy: 0.5778\nEpoch 91/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.5727 - val_loss: 0.1801 - val_accuracy: 0.5704\nEpoch 92/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.5610 - val_loss: 0.1797 - val_accuracy: 0.5778\nEpoch 93/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.5544 - val_loss: 0.1796 - val_accuracy: 0.5704\nEpoch 94/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.5622 - val_loss: 0.1795 - val_accuracy: 0.5704\nEpoch 95/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.5731 - val_loss: 0.1800 - val_accuracy: 0.5778\nEpoch 96/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.5789 - val_loss: 0.1800 - val_accuracy: 0.5778\nEpoch 97/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.5750 - val_loss: 0.1799 - val_accuracy: 0.5704\nEpoch 98/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.5653 - val_loss: 0.1805 - val_accuracy: 0.5704\nEpoch 99/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.5743 - val_loss: 0.1803 - val_accuracy: 0.5778\nEpoch 100/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.5743 - val_loss: 0.1802 - val_accuracy: 0.5778\nEpoch 101/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.5864 - val_loss: 0.1797 - val_accuracy: 0.5778\nEpoch 102/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.5669 - val_loss: 0.1797 - val_accuracy: 0.5778\nEpoch 103/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.5743 - val_loss: 0.1804 - val_accuracy: 0.5778\nEpoch 104/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.5750 - val_loss: 0.1794 - val_accuracy: 0.5778\nEpoch 105/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.5700 - val_loss: 0.1796 - val_accuracy: 0.5778\nEpoch 106/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.5805 - val_loss: 0.1794 - val_accuracy: 0.5778\nEpoch 107/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.5774 - val_loss: 0.1792 - val_accuracy: 0.5778\nEpoch 108/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.5782 - val_loss: 0.1790 - val_accuracy: 0.5778\nEpoch 109/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.5735 - val_loss: 0.1788 - val_accuracy: 0.5778\nEpoch 110/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.5844 - val_loss: 0.1802 - val_accuracy: 0.5778\nEpoch 111/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.5754 - val_loss: 0.1788 - val_accuracy: 0.5778\nEpoch 112/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1401 - accuracy: 0.5797 - val_loss: 0.1785 - val_accuracy: 0.5778\nEpoch 113/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.5805 - val_loss: 0.1787 - val_accuracy: 0.5704\nEpoch 114/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.5832 - val_loss: 0.1785 - val_accuracy: 0.5704\nEpoch 115/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.5809 - val_loss: 0.1790 - val_accuracy: 0.5630\nEpoch 116/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.5801 - val_loss: 0.1789 - val_accuracy: 0.5630\nEpoch 117/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.5879 - val_loss: 0.1789 - val_accuracy: 0.5778\nEpoch 118/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.5774 - val_loss: 0.1793 - val_accuracy: 0.5630\nEpoch 119/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1382 - accuracy: 0.5735 - val_loss: 0.1797 - val_accuracy: 0.5630\nEpoch 120/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.5797 - val_loss: 0.1784 - val_accuracy: 0.5630\nEpoch 121/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.5805 - val_loss: 0.1789 - val_accuracy: 0.5630\nEpoch 122/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.5793 - val_loss: 0.1790 - val_accuracy: 0.5630\nEpoch 123/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1373 - accuracy: 0.5832 - val_loss: 0.1786 - val_accuracy: 0.5630\nEpoch 124/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.5832 - val_loss: 0.1807 - val_accuracy: 0.5704\nEpoch 125/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.5883 - val_loss: 0.1791 - val_accuracy: 0.5630\nEpoch 126/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.5817 - val_loss: 0.1804 - val_accuracy: 0.5704\nEpoch 127/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.5754 - val_loss: 0.1798 - val_accuracy: 0.5704\nEpoch 128/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.5793 - val_loss: 0.1795 - val_accuracy: 0.5704\nEpoch 129/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.5860 - val_loss: 0.1790 - val_accuracy: 0.5704\nEpoch 130/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.5754 - val_loss: 0.1797 - val_accuracy: 0.5704\nEpoch 131/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.5801 - val_loss: 0.1798 - val_accuracy: 0.5704\nEpoch 132/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.5786 - val_loss: 0.1793 - val_accuracy: 0.5704\nEpoch 133/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.5836 - val_loss: 0.1792 - val_accuracy: 0.5704\nEpoch 134/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.5797 - val_loss: 0.1789 - val_accuracy: 0.5704\nEpoch 135/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.5793 - val_loss: 0.1793 - val_accuracy: 0.5704\nEpoch 136/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.5715 - val_loss: 0.1788 - val_accuracy: 0.5704\nEpoch 137/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.5856 - val_loss: 0.1791 - val_accuracy: 0.5630\nEpoch 138/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.5887 - val_loss: 0.1792 - val_accuracy: 0.5704\nEpoch 139/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.5836 - val_loss: 0.1781 - val_accuracy: 0.5704\nEpoch 140/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.5856 - val_loss: 0.1782 - val_accuracy: 0.5630\nEpoch 141/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.5782 - val_loss: 0.1781 - val_accuracy: 0.5704\nEpoch 142/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.5891 - val_loss: 0.1785 - val_accuracy: 0.5630\nEpoch 143/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.5860 - val_loss: 0.1791 - val_accuracy: 0.5630\nEpoch 144/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.5797 - val_loss: 0.1804 - val_accuracy: 0.5630\nEpoch 145/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.5860 - val_loss: 0.1801 - val_accuracy: 0.5630\nEpoch 146/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.5953 - val_loss: 0.1792 - val_accuracy: 0.5630\nEpoch 147/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.5762 - val_loss: 0.1795 - val_accuracy: 0.5630\nEpoch 148/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.5988 - val_loss: 0.1793 - val_accuracy: 0.5630\nEpoch 149/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.5934 - val_loss: 0.1797 - val_accuracy: 0.5704\nEpoch 150/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.5860 - val_loss: 0.1790 - val_accuracy: 0.5630\nEpoch 151/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.5871 - val_loss: 0.1794 - val_accuracy: 0.5630\nEpoch 152/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.5875 - val_loss: 0.1801 - val_accuracy: 0.5556\nEpoch 153/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.5926 - val_loss: 0.1802 - val_accuracy: 0.5630\nEpoch 154/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.5996 - val_loss: 0.1792 - val_accuracy: 0.5630\nEpoch 155/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.5953 - val_loss: 0.1796 - val_accuracy: 0.5556\nEpoch 156/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.5899 - val_loss: 0.1804 - val_accuracy: 0.5630\nEpoch 157/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.5957 - val_loss: 0.1802 - val_accuracy: 0.5630\nEpoch 158/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.5817 - val_loss: 0.1800 - val_accuracy: 0.5481\nEpoch 159/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.5926 - val_loss: 0.1798 - val_accuracy: 0.5481\nEpoch 160/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.5906 - val_loss: 0.1799 - val_accuracy: 0.5556\nEpoch 161/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.5965 - val_loss: 0.1790 - val_accuracy: 0.5556\nEpoch 162/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.5852 - val_loss: 0.1793 - val_accuracy: 0.5556\nEpoch 163/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.5825 - val_loss: 0.1796 - val_accuracy: 0.5630\nEpoch 164/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.5942 - val_loss: 0.1791 - val_accuracy: 0.5630\nEpoch 165/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.6008 - val_loss: 0.1813 - val_accuracy: 0.5556\nEpoch 166/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.6012 - val_loss: 0.1805 - val_accuracy: 0.5630\nEpoch 167/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.5903 - val_loss: 0.1803 - val_accuracy: 0.5630\nEpoch 168/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.5910 - val_loss: 0.1800 - val_accuracy: 0.5481\nEpoch 169/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.5903 - val_loss: 0.1792 - val_accuracy: 0.5556\nEpoch 170/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.5981 - val_loss: 0.1794 - val_accuracy: 0.5481\nEpoch 171/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.5926 - val_loss: 0.1797 - val_accuracy: 0.5556\nEpoch 172/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.5996 - val_loss: 0.1812 - val_accuracy: 0.5481\nEpoch 173/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.5922 - val_loss: 0.1802 - val_accuracy: 0.5481\nEpoch 174/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.5953 - val_loss: 0.1810 - val_accuracy: 0.5556\nEpoch 175/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.5934 - val_loss: 0.1802 - val_accuracy: 0.5556\nEpoch 176/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.5949 - val_loss: 0.1816 - val_accuracy: 0.5481\nEpoch 177/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.5949 - val_loss: 0.1806 - val_accuracy: 0.5630\nEpoch 178/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.5965 - val_loss: 0.1795 - val_accuracy: 0.5556\nEpoch 179/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.5938 - val_loss: 0.1810 - val_accuracy: 0.5556\nEpoch 180/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.5903 - val_loss: 0.1808 - val_accuracy: 0.5556\nEpoch 181/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.5992 - val_loss: 0.1811 - val_accuracy: 0.5630\nEpoch 182/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.6016 - val_loss: 0.1816 - val_accuracy: 0.5481\nEpoch 183/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.5887 - val_loss: 0.1818 - val_accuracy: 0.5481\nEpoch 184/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.5918 - val_loss: 0.1812 - val_accuracy: 0.5704\nEpoch 185/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.5949 - val_loss: 0.1809 - val_accuracy: 0.5556\nEpoch 186/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.6000 - val_loss: 0.1807 - val_accuracy: 0.5556\nEpoch 187/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.5883 - val_loss: 0.1808 - val_accuracy: 0.5630\nEpoch 188/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.5973 - val_loss: 0.1804 - val_accuracy: 0.5556\nEpoch 189/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.5918 - val_loss: 0.1806 - val_accuracy: 0.5556\nEpoch 190/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.5965 - val_loss: 0.1813 - val_accuracy: 0.5630\nEpoch 191/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.5899 - val_loss: 0.1814 - val_accuracy: 0.5556\nEpoch 192/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.5973 - val_loss: 0.1819 - val_accuracy: 0.5481\nEpoch 193/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.5969 - val_loss: 0.1810 - val_accuracy: 0.5556\nEpoch 194/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.5969 - val_loss: 0.1810 - val_accuracy: 0.5630\nEpoch 195/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.5977 - val_loss: 0.1806 - val_accuracy: 0.5556\nEpoch 196/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.5942 - val_loss: 0.1812 - val_accuracy: 0.5556\nEpoch 197/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.5938 - val_loss: 0.1807 - val_accuracy: 0.5630\nEpoch 198/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.5973 - val_loss: 0.1801 - val_accuracy: 0.5556\nEpoch 199/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.5984 - val_loss: 0.1813 - val_accuracy: 0.5556\nEpoch 200/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.5914 - val_loss: 0.1811 - val_accuracy: 0.5556\nEpoch 201/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.5965 - val_loss: 0.1810 - val_accuracy: 0.5556\nEpoch 202/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.5969 - val_loss: 0.1812 - val_accuracy: 0.5481\nEpoch 203/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.5938 - val_loss: 0.1811 - val_accuracy: 0.5481\nEpoch 204/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1224 - accuracy: 0.5961 - val_loss: 0.1808 - val_accuracy: 0.5556\nEpoch 205/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.6019 - val_loss: 0.1804 - val_accuracy: 0.5556\nEpoch 206/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.6031 - val_loss: 0.1829 - val_accuracy: 0.5481\nEpoch 207/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.6027 - val_loss: 0.1816 - val_accuracy: 0.5556\nEpoch 208/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1215 - accuracy: 0.6012 - val_loss: 0.1804 - val_accuracy: 0.5556\nEpoch 209/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.6094 - val_loss: 0.1797 - val_accuracy: 0.5630\nEpoch 210/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.5934 - val_loss: 0.1819 - val_accuracy: 0.5556\nEpoch 211/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.5973 - val_loss: 0.1814 - val_accuracy: 0.5556\nEpoch 212/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.5973 - val_loss: 0.1814 - val_accuracy: 0.5407\nEpoch 213/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.5984 - val_loss: 0.1824 - val_accuracy: 0.5481\nEpoch 214/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.5981 - val_loss: 0.1818 - val_accuracy: 0.5630\nEpoch 215/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.6027 - val_loss: 0.1820 - val_accuracy: 0.5556\nEpoch 216/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.5973 - val_loss: 0.1819 - val_accuracy: 0.5556\nEpoch 217/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.5836 - val_loss: 0.1821 - val_accuracy: 0.5556\nEpoch 218/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.5981 - val_loss: 0.1815 - val_accuracy: 0.5630\nEpoch 219/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.6055 - val_loss: 0.1811 - val_accuracy: 0.5556\nEpoch 220/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.6058 - val_loss: 0.1819 - val_accuracy: 0.5556\nEpoch 221/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.6004 - val_loss: 0.1832 - val_accuracy: 0.5630\nEpoch 222/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.6074 - val_loss: 0.1824 - val_accuracy: 0.5630\nEpoch 223/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.6000 - val_loss: 0.1825 - val_accuracy: 0.5481\nEpoch 224/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.5988 - val_loss: 0.1840 - val_accuracy: 0.5556\nEpoch 225/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.6000 - val_loss: 0.1830 - val_accuracy: 0.5630\nEpoch 226/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.5996 - val_loss: 0.1832 - val_accuracy: 0.5481\nEpoch 227/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.5934 - val_loss: 0.1822 - val_accuracy: 0.5556\nEpoch 228/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.5973 - val_loss: 0.1827 - val_accuracy: 0.5630\nEpoch 229/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.6031 - val_loss: 0.1828 - val_accuracy: 0.5704\nEpoch 230/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.5984 - val_loss: 0.1826 - val_accuracy: 0.5556\nEpoch 231/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.6027 - val_loss: 0.1831 - val_accuracy: 0.5481\nEpoch 232/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.6039 - val_loss: 0.1821 - val_accuracy: 0.5704\nEpoch 233/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.6109 - val_loss: 0.1830 - val_accuracy: 0.5481\nEpoch 234/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.5895 - val_loss: 0.1819 - val_accuracy: 0.5556\nEpoch 235/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.6012 - val_loss: 0.1829 - val_accuracy: 0.5630\nEpoch 236/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.6066 - val_loss: 0.1830 - val_accuracy: 0.5704\nEpoch 237/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.6016 - val_loss: 0.1826 - val_accuracy: 0.5481\nEpoch 238/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.6023 - val_loss: 0.1829 - val_accuracy: 0.5481\nEpoch 239/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.6000 - val_loss: 0.1826 - val_accuracy: 0.5556\nEpoch 240/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.6074 - val_loss: 0.1822 - val_accuracy: 0.5556\nEpoch 241/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.6094 - val_loss: 0.1824 - val_accuracy: 0.5556\nEpoch 242/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.6035 - val_loss: 0.1831 - val_accuracy: 0.5556\nEpoch 243/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.5914 - val_loss: 0.1841 - val_accuracy: 0.5481\nEpoch 244/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.6117 - val_loss: 0.1834 - val_accuracy: 0.5556\nEpoch 245/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.6125 - val_loss: 0.1836 - val_accuracy: 0.5556\nEpoch 246/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.6035 - val_loss: 0.1839 - val_accuracy: 0.5556\nEpoch 247/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.6074 - val_loss: 0.1835 - val_accuracy: 0.5556\nEpoch 248/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.6097 - val_loss: 0.1844 - val_accuracy: 0.5481\nEpoch 249/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.6086 - val_loss: 0.1834 - val_accuracy: 0.5704\nEpoch 250/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.6129 - val_loss: 0.1827 - val_accuracy: 0.5630\nEpoch 251/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.6047 - val_loss: 0.1833 - val_accuracy: 0.5481\nEpoch 252/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.6016 - val_loss: 0.1830 - val_accuracy: 0.5556\nEpoch 253/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.5981 - val_loss: 0.1840 - val_accuracy: 0.5481\nEpoch 254/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.6070 - val_loss: 0.1834 - val_accuracy: 0.5407\nEpoch 255/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.6012 - val_loss: 0.1839 - val_accuracy: 0.5481\nEpoch 256/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.6105 - val_loss: 0.1833 - val_accuracy: 0.5556\nEpoch 257/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.6094 - val_loss: 0.1842 - val_accuracy: 0.5556\nEpoch 258/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.6129 - val_loss: 0.1851 - val_accuracy: 0.5481\nEpoch 259/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.6094 - val_loss: 0.1837 - val_accuracy: 0.5556\nEpoch 260/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.6140 - val_loss: 0.1836 - val_accuracy: 0.5481\nEpoch 261/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.6058 - val_loss: 0.1866 - val_accuracy: 0.5556\nEpoch 262/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.6008 - val_loss: 0.1842 - val_accuracy: 0.5481\nEpoch 263/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.6144 - val_loss: 0.1852 - val_accuracy: 0.5556\nEpoch 264/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.6043 - val_loss: 0.1835 - val_accuracy: 0.5407\nEpoch 265/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.6055 - val_loss: 0.1838 - val_accuracy: 0.5481\nEpoch 266/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.5992 - val_loss: 0.1845 - val_accuracy: 0.5556\nEpoch 267/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.6109 - val_loss: 0.1829 - val_accuracy: 0.5481\nEpoch 268/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.6051 - val_loss: 0.1838 - val_accuracy: 0.5630\nEpoch 269/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.6117 - val_loss: 0.1839 - val_accuracy: 0.5630\nEpoch 270/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.6058 - val_loss: 0.1847 - val_accuracy: 0.5556\nEpoch 271/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.6027 - val_loss: 0.1836 - val_accuracy: 0.5481\nEpoch 272/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.6051 - val_loss: 0.1835 - val_accuracy: 0.5556\nEpoch 273/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.6012 - val_loss: 0.1852 - val_accuracy: 0.5481\nEpoch 274/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.6203 - val_loss: 0.1837 - val_accuracy: 0.5556\nEpoch 275/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.6070 - val_loss: 0.1850 - val_accuracy: 0.5481\nEpoch 276/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.6074 - val_loss: 0.1852 - val_accuracy: 0.5630\nEpoch 277/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.6105 - val_loss: 0.1855 - val_accuracy: 0.5556\nEpoch 278/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.6023 - val_loss: 0.1854 - val_accuracy: 0.5556\nEpoch 279/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.6035 - val_loss: 0.1852 - val_accuracy: 0.5556\nEpoch 280/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.6031 - val_loss: 0.1854 - val_accuracy: 0.5556\nEpoch 281/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.6070 - val_loss: 0.1859 - val_accuracy: 0.5556\nEpoch 282/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.6144 - val_loss: 0.1853 - val_accuracy: 0.5481\nEpoch 283/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.6109 - val_loss: 0.1847 - val_accuracy: 0.5481\nEpoch 284/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.6051 - val_loss: 0.1852 - val_accuracy: 0.5556\nEpoch 285/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.6133 - val_loss: 0.1839 - val_accuracy: 0.5556\nEpoch 286/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.6051 - val_loss: 0.1845 - val_accuracy: 0.5630\nEpoch 287/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.6187 - val_loss: 0.1847 - val_accuracy: 0.5556\nEpoch 288/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.6125 - val_loss: 0.1844 - val_accuracy: 0.5556\nEpoch 289/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.6160 - val_loss: 0.1841 - val_accuracy: 0.5704\nEpoch 290/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.6035 - val_loss: 0.1847 - val_accuracy: 0.5630\nEpoch 291/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.6164 - val_loss: 0.1853 - val_accuracy: 0.5556\nEpoch 292/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.6066 - val_loss: 0.1860 - val_accuracy: 0.5481\nEpoch 293/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.6097 - val_loss: 0.1840 - val_accuracy: 0.5556\nEpoch 294/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.6140 - val_loss: 0.1842 - val_accuracy: 0.5630\nEpoch 295/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.6090 - val_loss: 0.1836 - val_accuracy: 0.5630\nEpoch 296/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.6187 - val_loss: 0.1840 - val_accuracy: 0.5630\nEpoch 297/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.6047 - val_loss: 0.1835 - val_accuracy: 0.5630\nEpoch 298/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.6051 - val_loss: 0.1844 - val_accuracy: 0.5556\nEpoch 299/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.6109 - val_loss: 0.1839 - val_accuracy: 0.5481\nEpoch 300/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.6168 - val_loss: 0.1852 - val_accuracy: 0.5556\nEpoch 301/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.6090 - val_loss: 0.1848 - val_accuracy: 0.5481\nEpoch 302/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.6136 - val_loss: 0.1850 - val_accuracy: 0.5556\nEpoch 303/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.6140 - val_loss: 0.1848 - val_accuracy: 0.5630\nEpoch 304/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.6183 - val_loss: 0.1853 - val_accuracy: 0.5481\nEpoch 305/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.6078 - val_loss: 0.1861 - val_accuracy: 0.5630\nEpoch 306/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.6125 - val_loss: 0.1854 - val_accuracy: 0.5481\nEpoch 307/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.6136 - val_loss: 0.1852 - val_accuracy: 0.5704\nEpoch 308/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.6094 - val_loss: 0.1854 - val_accuracy: 0.5630\nEpoch 309/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.6090 - val_loss: 0.1861 - val_accuracy: 0.5556\nEpoch 310/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.6062 - val_loss: 0.1865 - val_accuracy: 0.5556\nEpoch 311/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.5996 - val_loss: 0.1844 - val_accuracy: 0.5556\nEpoch 312/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.6238 - val_loss: 0.1859 - val_accuracy: 0.5630\nEpoch 313/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.6082 - val_loss: 0.1865 - val_accuracy: 0.5630\nEpoch 314/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.6101 - val_loss: 0.1867 - val_accuracy: 0.5630\nEpoch 315/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.6074 - val_loss: 0.1872 - val_accuracy: 0.5630\nEpoch 316/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.6168 - val_loss: 0.1864 - val_accuracy: 0.5630\nEpoch 317/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.6133 - val_loss: 0.1858 - val_accuracy: 0.5481\nEpoch 318/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.6117 - val_loss: 0.1860 - val_accuracy: 0.5407\nEpoch 319/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.6066 - val_loss: 0.1861 - val_accuracy: 0.5556\nEpoch 320/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.6101 - val_loss: 0.1864 - val_accuracy: 0.5704\nEpoch 321/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.6191 - val_loss: 0.1860 - val_accuracy: 0.5481\nEpoch 322/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.6164 - val_loss: 0.1854 - val_accuracy: 0.5630\nEpoch 323/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.6238 - val_loss: 0.1858 - val_accuracy: 0.5556\nEpoch 324/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.6109 - val_loss: 0.1858 - val_accuracy: 0.5630\nEpoch 325/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.6269 - val_loss: 0.1851 - val_accuracy: 0.5630\nEpoch 326/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.6086 - val_loss: 0.1857 - val_accuracy: 0.5630\nEpoch 327/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.6164 - val_loss: 0.1862 - val_accuracy: 0.5630\nEpoch 328/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.6105 - val_loss: 0.1867 - val_accuracy: 0.5481\nEpoch 329/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.6129 - val_loss: 0.1869 - val_accuracy: 0.5481\nEpoch 330/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.6199 - val_loss: 0.1862 - val_accuracy: 0.5630\nEpoch 331/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.6117 - val_loss: 0.1860 - val_accuracy: 0.5630\nEpoch 332/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.6129 - val_loss: 0.1866 - val_accuracy: 0.5556\nEpoch 333/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.6164 - val_loss: 0.1859 - val_accuracy: 0.5481\nEpoch 334/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.6125 - val_loss: 0.1867 - val_accuracy: 0.5556\nEpoch 335/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.6113 - val_loss: 0.1854 - val_accuracy: 0.5630\nEpoch 336/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.6113 - val_loss: 0.1864 - val_accuracy: 0.5556\nEpoch 337/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.6164 - val_loss: 0.1865 - val_accuracy: 0.5630\nEpoch 338/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.6136 - val_loss: 0.1863 - val_accuracy: 0.5630\nEpoch 339/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.6140 - val_loss: 0.1879 - val_accuracy: 0.5630\nEpoch 340/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.6082 - val_loss: 0.1871 - val_accuracy: 0.5630\nEpoch 341/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.6269 - val_loss: 0.1859 - val_accuracy: 0.5481\nEpoch 342/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.6238 - val_loss: 0.1857 - val_accuracy: 0.5704\nEpoch 343/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.6113 - val_loss: 0.1864 - val_accuracy: 0.5407\nEpoch 344/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.6136 - val_loss: 0.1873 - val_accuracy: 0.5556\nEpoch 345/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.6179 - val_loss: 0.1881 - val_accuracy: 0.5481\nEpoch 346/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.6226 - val_loss: 0.1881 - val_accuracy: 0.5630\nEpoch 347/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.6082 - val_loss: 0.1866 - val_accuracy: 0.5556\nEpoch 348/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.6191 - val_loss: 0.1875 - val_accuracy: 0.5630\nEpoch 349/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.6168 - val_loss: 0.1878 - val_accuracy: 0.5630\nEpoch 350/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.6133 - val_loss: 0.1871 - val_accuracy: 0.5556\nEpoch 351/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.6191 - val_loss: 0.1887 - val_accuracy: 0.5556\nEpoch 352/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.6238 - val_loss: 0.1872 - val_accuracy: 0.5556\nEpoch 353/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.6055 - val_loss: 0.1877 - val_accuracy: 0.5556\nEpoch 354/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.6211 - val_loss: 0.1895 - val_accuracy: 0.5630\nEpoch 355/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.6183 - val_loss: 0.1887 - val_accuracy: 0.5630\nEpoch 356/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.6164 - val_loss: 0.1865 - val_accuracy: 0.5481\nEpoch 357/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.6187 - val_loss: 0.1878 - val_accuracy: 0.5556\nEpoch 358/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.6218 - val_loss: 0.1874 - val_accuracy: 0.5556\nEpoch 359/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.6160 - val_loss: 0.1881 - val_accuracy: 0.5630\nEpoch 360/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.6199 - val_loss: 0.1877 - val_accuracy: 0.5630\nEpoch 361/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.6117 - val_loss: 0.1878 - val_accuracy: 0.5556\nEpoch 362/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.6133 - val_loss: 0.1885 - val_accuracy: 0.5630\nEpoch 363/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.6203 - val_loss: 0.1867 - val_accuracy: 0.5630\nEpoch 364/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.6308 - val_loss: 0.1877 - val_accuracy: 0.5704\nEpoch 365/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.6265 - val_loss: 0.1869 - val_accuracy: 0.5556\nEpoch 366/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.6156 - val_loss: 0.1870 - val_accuracy: 0.5481\nEpoch 367/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.6172 - val_loss: 0.1887 - val_accuracy: 0.5556\nEpoch 368/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.6175 - val_loss: 0.1874 - val_accuracy: 0.5481\nEpoch 369/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.6133 - val_loss: 0.1872 - val_accuracy: 0.5481\nEpoch 370/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.6218 - val_loss: 0.1881 - val_accuracy: 0.5481\nEpoch 371/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.6183 - val_loss: 0.1886 - val_accuracy: 0.5481\nEpoch 372/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.6172 - val_loss: 0.1878 - val_accuracy: 0.5481\nEpoch 373/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.6199 - val_loss: 0.1873 - val_accuracy: 0.5407\nEpoch 374/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.6160 - val_loss: 0.1870 - val_accuracy: 0.5556\nEpoch 375/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.6183 - val_loss: 0.1881 - val_accuracy: 0.5556\nEpoch 376/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.6152 - val_loss: 0.1883 - val_accuracy: 0.5481\nEpoch 377/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.6226 - val_loss: 0.1867 - val_accuracy: 0.5556\nEpoch 378/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.6285 - val_loss: 0.1879 - val_accuracy: 0.5556\nEpoch 379/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.6187 - val_loss: 0.1872 - val_accuracy: 0.5556\nEpoch 380/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.6133 - val_loss: 0.1878 - val_accuracy: 0.5556\nEpoch 381/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.6199 - val_loss: 0.1869 - val_accuracy: 0.5556\nEpoch 382/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.6222 - val_loss: 0.1888 - val_accuracy: 0.5556\nEpoch 383/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.6187 - val_loss: 0.1882 - val_accuracy: 0.5630\nEpoch 384/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.6179 - val_loss: 0.1883 - val_accuracy: 0.5630\nEpoch 385/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.6238 - val_loss: 0.1880 - val_accuracy: 0.5556\nEpoch 386/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.6242 - val_loss: 0.1886 - val_accuracy: 0.5630\nEpoch 387/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.6168 - val_loss: 0.1883 - val_accuracy: 0.5556\nEpoch 388/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.6152 - val_loss: 0.1891 - val_accuracy: 0.5556\nEpoch 389/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.6172 - val_loss: 0.1881 - val_accuracy: 0.5556\nEpoch 390/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.6195 - val_loss: 0.1882 - val_accuracy: 0.5630\nEpoch 391/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.6222 - val_loss: 0.1881 - val_accuracy: 0.5556\nEpoch 392/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.6257 - val_loss: 0.1874 - val_accuracy: 0.5556\nEpoch 393/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.6160 - val_loss: 0.1874 - val_accuracy: 0.5704\nEpoch 394/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.6269 - val_loss: 0.1888 - val_accuracy: 0.5704\nEpoch 395/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.6261 - val_loss: 0.1883 - val_accuracy: 0.5556\nEpoch 396/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.6253 - val_loss: 0.1886 - val_accuracy: 0.5630\nEpoch 397/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.6281 - val_loss: 0.1889 - val_accuracy: 0.5556\nEpoch 398/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.6226 - val_loss: 0.1882 - val_accuracy: 0.5630\nEpoch 399/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.6175 - val_loss: 0.1882 - val_accuracy: 0.5630\nEpoch 400/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.6250 - val_loss: 0.1888 - val_accuracy: 0.5630\nEpoch 401/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.6226 - val_loss: 0.1891 - val_accuracy: 0.5704\nEpoch 402/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.6187 - val_loss: 0.1894 - val_accuracy: 0.5630\nEpoch 403/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.6230 - val_loss: 0.1881 - val_accuracy: 0.5630\nEpoch 404/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.6172 - val_loss: 0.1886 - val_accuracy: 0.5630\nEpoch 405/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.6250 - val_loss: 0.1891 - val_accuracy: 0.5704\nEpoch 406/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.6183 - val_loss: 0.1893 - val_accuracy: 0.5778\nEpoch 407/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.6101 - val_loss: 0.1895 - val_accuracy: 0.5630\nEpoch 408/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.6156 - val_loss: 0.1891 - val_accuracy: 0.5630\nEpoch 409/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.6187 - val_loss: 0.1888 - val_accuracy: 0.5630\nEpoch 410/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.6207 - val_loss: 0.1890 - val_accuracy: 0.5630\nEpoch 411/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.6320 - val_loss: 0.1881 - val_accuracy: 0.5630\nEpoch 412/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.6175 - val_loss: 0.1879 - val_accuracy: 0.5630\nEpoch 413/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.6218 - val_loss: 0.1885 - val_accuracy: 0.5630\nEpoch 414/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.6246 - val_loss: 0.1889 - val_accuracy: 0.5630\nEpoch 415/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.6273 - val_loss: 0.1887 - val_accuracy: 0.5630\nEpoch 416/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.6253 - val_loss: 0.1869 - val_accuracy: 0.5556\nEpoch 417/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.6164 - val_loss: 0.1877 - val_accuracy: 0.5556\nEpoch 418/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.6250 - val_loss: 0.1891 - val_accuracy: 0.5630\nEpoch 419/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.6300 - val_loss: 0.1878 - val_accuracy: 0.5630\nEpoch 420/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.6211 - val_loss: 0.1885 - val_accuracy: 0.5704\nEpoch 421/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.6288 - val_loss: 0.1883 - val_accuracy: 0.5556\nEpoch 422/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.6125 - val_loss: 0.1880 - val_accuracy: 0.5630\nEpoch 423/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.6187 - val_loss: 0.1879 - val_accuracy: 0.5704\nEpoch 424/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.6273 - val_loss: 0.1892 - val_accuracy: 0.5556\nEpoch 425/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.6312 - val_loss: 0.1891 - val_accuracy: 0.5704\nEpoch 426/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.6253 - val_loss: 0.1884 - val_accuracy: 0.5556\nEpoch 427/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.6234 - val_loss: 0.1890 - val_accuracy: 0.5630\nEpoch 428/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.6160 - val_loss: 0.1888 - val_accuracy: 0.5630\nEpoch 429/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.6234 - val_loss: 0.1900 - val_accuracy: 0.5556\nEpoch 430/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.6281 - val_loss: 0.1899 - val_accuracy: 0.5630\nEpoch 431/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.6230 - val_loss: 0.1891 - val_accuracy: 0.5630\nEpoch 432/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.6195 - val_loss: 0.1900 - val_accuracy: 0.5630\nEpoch 433/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.6273 - val_loss: 0.1898 - val_accuracy: 0.5556\nEpoch 434/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.6195 - val_loss: 0.1902 - val_accuracy: 0.5630\nEpoch 435/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.6164 - val_loss: 0.1900 - val_accuracy: 0.5630\nEpoch 436/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.6242 - val_loss: 0.1891 - val_accuracy: 0.5630\nEpoch 437/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.6234 - val_loss: 0.1899 - val_accuracy: 0.5630\nEpoch 438/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.6179 - val_loss: 0.1893 - val_accuracy: 0.5630\nEpoch 439/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.6183 - val_loss: 0.1885 - val_accuracy: 0.5704\nEpoch 440/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.6285 - val_loss: 0.1890 - val_accuracy: 0.5630\nEpoch 441/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.6288 - val_loss: 0.1894 - val_accuracy: 0.5704\nEpoch 442/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.6288 - val_loss: 0.1886 - val_accuracy: 0.5630\nEpoch 443/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.6207 - val_loss: 0.1901 - val_accuracy: 0.5630\nEpoch 444/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.6269 - val_loss: 0.1897 - val_accuracy: 0.5630\nEpoch 445/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.6211 - val_loss: 0.1904 - val_accuracy: 0.5704\nEpoch 446/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.6187 - val_loss: 0.1898 - val_accuracy: 0.5704\nEpoch 447/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.6218 - val_loss: 0.1903 - val_accuracy: 0.5704\nEpoch 448/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.6250 - val_loss: 0.1909 - val_accuracy: 0.5630\nEpoch 449/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.6285 - val_loss: 0.1908 - val_accuracy: 0.5704\nEpoch 450/500\n41/41 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.6265 - val_loss: 0.1908 - val_accuracy: 0.5704\nEpoch 451/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.6265 - val_loss: 0.1904 - val_accuracy: 0.5704\nEpoch 452/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.6312 - val_loss: 0.1909 - val_accuracy: 0.5704\nEpoch 453/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.6304 - val_loss: 0.1903 - val_accuracy: 0.5704\nEpoch 454/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.6183 - val_loss: 0.1893 - val_accuracy: 0.5704\nEpoch 455/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.6288 - val_loss: 0.1901 - val_accuracy: 0.5704\nEpoch 456/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.6300 - val_loss: 0.1899 - val_accuracy: 0.5630\nEpoch 457/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.6226 - val_loss: 0.1901 - val_accuracy: 0.5704\nEpoch 458/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.6269 - val_loss: 0.1897 - val_accuracy: 0.5704\nEpoch 459/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.6222 - val_loss: 0.1897 - val_accuracy: 0.5556\nEpoch 460/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.6218 - val_loss: 0.1900 - val_accuracy: 0.5704\nEpoch 461/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.6250 - val_loss: 0.1895 - val_accuracy: 0.5630\nEpoch 462/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.6288 - val_loss: 0.1896 - val_accuracy: 0.5778\nEpoch 463/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.6199 - val_loss: 0.1911 - val_accuracy: 0.5704\nEpoch 464/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.6250 - val_loss: 0.1910 - val_accuracy: 0.5630\nEpoch 465/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.6347 - val_loss: 0.1917 - val_accuracy: 0.5630\nEpoch 466/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.6214 - val_loss: 0.1904 - val_accuracy: 0.5704\nEpoch 467/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.6160 - val_loss: 0.1906 - val_accuracy: 0.5704\nEpoch 468/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.6113 - val_loss: 0.1905 - val_accuracy: 0.5704\nEpoch 469/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.6191 - val_loss: 0.1904 - val_accuracy: 0.5704\nEpoch 470/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.6312 - val_loss: 0.1898 - val_accuracy: 0.5778\nEpoch 471/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.6222 - val_loss: 0.1899 - val_accuracy: 0.5704\nEpoch 472/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.6172 - val_loss: 0.1908 - val_accuracy: 0.5778\nEpoch 473/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.6331 - val_loss: 0.1906 - val_accuracy: 0.5704\nEpoch 474/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.6187 - val_loss: 0.1918 - val_accuracy: 0.5704\nEpoch 475/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.6211 - val_loss: 0.1908 - val_accuracy: 0.5704\nEpoch 476/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.6285 - val_loss: 0.1907 - val_accuracy: 0.5630\nEpoch 477/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6172 - val_loss: 0.1915 - val_accuracy: 0.5704\nEpoch 478/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6312 - val_loss: 0.1911 - val_accuracy: 0.5704\nEpoch 479/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.6207 - val_loss: 0.1913 - val_accuracy: 0.5556\nEpoch 480/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6253 - val_loss: 0.1913 - val_accuracy: 0.5630\nEpoch 481/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6363 - val_loss: 0.1908 - val_accuracy: 0.5704\nEpoch 482/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6335 - val_loss: 0.1917 - val_accuracy: 0.5630\nEpoch 483/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.6308 - val_loss: 0.1911 - val_accuracy: 0.5630\nEpoch 484/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.6222 - val_loss: 0.1927 - val_accuracy: 0.5630\nEpoch 485/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.6335 - val_loss: 0.1906 - val_accuracy: 0.5630\nEpoch 486/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.6246 - val_loss: 0.1907 - val_accuracy: 0.5704\nEpoch 487/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.6277 - val_loss: 0.1910 - val_accuracy: 0.5630\nEpoch 488/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.6230 - val_loss: 0.1911 - val_accuracy: 0.5778\nEpoch 489/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.6351 - val_loss: 0.1920 - val_accuracy: 0.5704\nEpoch 490/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.6288 - val_loss: 0.1925 - val_accuracy: 0.5704\nEpoch 491/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.6327 - val_loss: 0.1918 - val_accuracy: 0.5778\nEpoch 492/500\n41/41 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.6222 - val_loss: 0.1910 - val_accuracy: 0.5778\nEpoch 493/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.6343 - val_loss: 0.1900 - val_accuracy: 0.5778\nEpoch 494/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.6316 - val_loss: 0.1923 - val_accuracy: 0.5778\nEpoch 495/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.6288 - val_loss: 0.1904 - val_accuracy: 0.5778\nEpoch 496/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.6285 - val_loss: 0.1916 - val_accuracy: 0.5778\nEpoch 497/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.6378 - val_loss: 0.1926 - val_accuracy: 0.5778\nEpoch 498/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.6300 - val_loss: 0.1897 - val_accuracy: 0.5778\nEpoch 499/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.6343 - val_loss: 0.1908 - val_accuracy: 0.5630\nEpoch 500/500\n41/41 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.6203 - val_loss: 0.1915 - val_accuracy: 0.5704\n"
    }
   ],
   "source": [
    "def wMSE(y_true, y_pred, binary=False):\n",
    "    if binary:\n",
    "        weights = tf.cast(y_true>0, tf.float32)\n",
    "    else:\n",
    "        weights = y_true\n",
    "    return tf.reduce_mean(weights*tf.square(y_true-y_pred)) \n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=wMSE, metrics=[\"accuracy\"]) # using same optimizer and loss function as DeepImpute \n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=500, batch_size=64)\n",
    "#                    callbacks=[EarlyStopping(monitor='val_loss', patience=5)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7fe621f02880>"
     },
     "metadata": {},
     "execution_count": 400
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.0, 1.0)"
     },
     "metadata": {},
     "execution_count": 400
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"306.677344pt\" version=\"1.1\" viewBox=\"0 0 483.703125 306.677344\" width=\"483.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 306.677344 \nL 483.703125 306.677344 \nL 483.703125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 282.799219 \nL 476.503125 282.799219 \nL 476.503125 10.999219 \nL 30.103125 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 50.394034 282.799219 \nL 50.394034 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1ccd64bfc7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.394034\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(47.212784 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 131.720323 282.799219 \nL 131.720323 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"131.720323\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(122.176573 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 213.046612 282.799219 \nL 213.046612 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"213.046612\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(203.502862 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 294.372901 282.799219 \nL 294.372901 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.372901\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(284.829151 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 375.69919 282.799219 \nL 375.69919 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.69919\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(366.15544 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 457.025479 282.799219 \nL 457.025479 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"457.025479\" xlink:href=\"#m1ccd64bfc7\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(447.481729 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 282.799219 \nL 476.503125 282.799219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf59ca00968\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 286.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 228.439219 \nL 476.503125 228.439219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 174.079219 \nL 476.503125 174.079219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"174.079219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 177.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 119.719219 \nL 476.503125 119.719219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"119.719219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 65.359219 \nL 476.503125 65.359219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"65.359219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p97718cc0d7)\" d=\"M 30.103125 10.999219 \nL 476.503125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf59ca00968\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p97718cc0d7)\" d=\"M 51.517932 -1 \nL 52.02056 110.920827 \nL 52.833823 156.934507 \nL 53.647086 170.999138 \nL 54.460349 178.887611 \nL 55.273611 185.635834 \nL 56.086874 190.933362 \nL 56.900137 195.314815 \nL 58.526663 203.07724 \nL 60.153189 207.532106 \nL 60.966452 209.911059 \nL 61.779715 211.44205 \nL 63.40624 214.857088 \nL 64.219503 215.924902 \nL 65.032766 217.38283 \nL 65.846029 218.106403 \nL 67.472555 220.775086 \nL 69.099081 222.196626 \nL 70.725606 224.433383 \nL 71.538869 224.282985 \nL 72.352132 225.53986 \nL 73.165395 226.124541 \nL 73.978658 226.980254 \nL 77.231709 229.298908 \nL 78.044972 229.648921 \nL 78.858235 230.440977 \nL 80.484761 231.240207 \nL 81.298024 231.753059 \nL 82.92455 232.368919 \nL 83.737813 233.049301 \nL 84.551075 233.50439 \nL 88.61739 235.109994 \nL 89.430653 235.554168 \nL 90.243916 235.765055 \nL 91.870441 236.376581 \nL 92.683704 236.736549 \nL 96.750019 237.880384 \nL 97.563282 238.267682 \nL 98.376545 238.313971 \nL 100.00307 238.717587 \nL 101.629596 239.306234 \nL 102.442859 239.236539 \nL 103.256122 239.612825 \nL 105.695911 240.00323 \nL 106.509173 240.209058 \nL 108.135699 240.405514 \nL 112.202014 241.209599 \nL 113.015277 241.473522 \nL 113.828539 241.361811 \nL 116.268328 241.877151 \nL 117.081591 241.889605 \nL 117.894854 242.188902 \nL 118.708117 242.110645 \nL 119.52138 242.240614 \nL 120.334643 242.533058 \nL 121.961168 242.437888 \nL 122.774431 242.830383 \nL 124.400957 242.984604 \nL 126.027483 243.122543 \nL 126.840746 243.315382 \nL 127.654009 243.1927 \nL 128.467271 243.418158 \nL 130.093797 243.595947 \nL 130.90706 243.795003 \nL 131.720323 243.650377 \nL 133.346849 243.943955 \nL 134.160112 243.854751 \nL 135.786637 244.164254 \nL 137.413163 244.282648 \nL 139.039689 244.651089 \nL 139.852952 244.560058 \nL 141.479478 244.824139 \nL 142.292741 244.741216 \nL 144.732529 245.234527 \nL 147.172318 245.142378 \nL 147.985581 245.411862 \nL 148.798844 245.362973 \nL 151.238632 245.631878 \nL 152.051895 245.504805 \nL 152.865158 245.776638 \nL 154.491684 245.896449 \nL 155.304947 246.07862 \nL 156.11821 245.98771 \nL 156.931473 246.136804 \nL 158.557998 246.1365 \nL 159.371261 246.301341 \nL 160.997787 246.338776 \nL 163.437576 246.713592 \nL 165.877364 246.700214 \nL 169.130416 247.015764 \nL 169.943679 247.029029 \nL 170.756942 247.158313 \nL 171.570205 247.034909 \nL 173.19673 247.382447 \nL 174.823256 247.305402 \nL 176.449782 247.47279 \nL 177.263045 247.383245 \nL 178.889571 247.753873 \nL 179.702834 247.611422 \nL 181.329359 247.780418 \nL 182.955885 248.034981 \nL 183.769148 247.920459 \nL 187.0222 248.141544 \nL 187.835462 248.179866 \nL 188.648725 248.336838 \nL 189.461988 248.190498 \nL 190.275251 248.322273 \nL 191.088514 248.234936 \nL 195.968091 248.742086 \nL 196.781354 248.511407 \nL 197.594617 248.647665 \nL 199.221143 248.734172 \nL 200.034406 248.990133 \nL 200.847669 248.750717 \nL 203.287457 248.979712 \nL 208.980298 249.228734 \nL 209.79356 249.425739 \nL 210.606823 249.372307 \nL 211.420086 249.495357 \nL 212.233349 249.385582 \nL 213.859875 249.681365 \nL 214.673138 249.677694 \nL 215.486401 249.523639 \nL 216.299664 249.633989 \nL 217.112926 249.383127 \nL 217.926189 249.653257 \nL 218.739452 249.763158 \nL 221.179241 249.722871 \nL 221.992504 249.923397 \nL 223.61903 249.943034 \nL 226.872081 250.058959 \nL 228.498607 250.099653 \nL 232.564921 250.302372 \nL 235.00471 250.399521 \nL 235.817973 250.474718 \nL 237.444499 250.370528 \nL 238.257762 250.500226 \nL 239.071024 250.398365 \nL 242.324076 250.746166 \nL 243.950602 250.643532 \nL 247.203653 250.878454 \nL 248.016916 250.8103 \nL 248.830179 250.919558 \nL 251.269968 250.907272 \nL 252.896494 251.067461 \nL 253.709756 251.006262 \nL 255.336282 251.109767 \nL 256.149545 250.911314 \nL 257.776071 251.167441 \nL 258.589334 251.229455 \nL 260.21586 251.182896 \nL 261.029122 251.322662 \nL 261.842385 251.167694 \nL 262.655648 251.328985 \nL 268.348488 251.51794 \nL 269.161751 251.62426 \nL 269.975014 251.514533 \nL 274.041329 251.627002 \nL 274.854592 251.769479 \nL 275.667854 251.549186 \nL 277.29438 251.936851 \nL 278.107643 251.71554 \nL 278.920906 251.642728 \nL 279.734169 251.969447 \nL 280.547432 251.770107 \nL 281.360695 251.782179 \nL 282.173958 251.964538 \nL 282.98722 251.894491 \nL 283.800483 252.092864 \nL 284.613746 251.975285 \nL 285.427009 252.023763 \nL 286.240272 251.93612 \nL 291.933112 252.16181 \nL 292.746375 251.81861 \nL 293.559638 252.221298 \nL 294.372901 252.053675 \nL 295.999427 252.179511 \nL 296.81269 252.134435 \nL 300.879004 252.457466 \nL 301.692267 252.272079 \nL 304.132056 252.531118 \nL 304.945318 252.404603 \nL 308.19837 252.618862 \nL 309.011633 252.534623 \nL 309.824896 252.620749 \nL 310.638159 252.425429 \nL 311.451422 252.717472 \nL 312.264684 252.63003 \nL 313.077947 252.778652 \nL 314.704473 252.613189 \nL 315.517736 252.754399 \nL 316.330999 252.637905 \nL 319.58405 252.84004 \nL 320.397313 252.772674 \nL 321.210576 252.89407 \nL 323.650365 252.788204 \nL 324.463628 253.055703 \nL 325.276891 252.910135 \nL 328.529942 252.927338 \nL 329.343205 253.096996 \nL 330.156468 252.992021 \nL 330.969731 253.095593 \nL 332.596257 253.055568 \nL 334.222782 253.066005 \nL 335.036045 252.668123 \nL 335.849308 252.994165 \nL 336.662571 252.968105 \nL 337.475834 253.166073 \nL 341.542149 253.341926 \nL 343.168674 253.328202 \nL 343.981937 253.458805 \nL 347.234989 253.363868 \nL 349.674777 253.46401 \nL 350.48804 253.305262 \nL 351.301303 253.530819 \nL 352.927829 253.575332 \nL 355.367618 253.436981 \nL 356.994143 253.570664 \nL 357.807406 253.484564 \nL 359.433932 253.763495 \nL 360.247195 253.565401 \nL 361.060458 253.700558 \nL 361.873721 253.715391 \nL 362.686984 253.572632 \nL 364.313509 253.740198 \nL 365.126772 253.695943 \nL 366.753298 253.893812 \nL 367.566561 253.741948 \nL 372.446138 253.986499 \nL 374.072664 253.715122 \nL 374.885927 253.901862 \nL 378.138979 254.055295 \nL 378.952241 253.994278 \nL 379.765504 254.131984 \nL 380.578767 253.929038 \nL 381.39203 254.0759 \nL 383.831819 253.99871 \nL 385.458345 254.143284 \nL 386.271607 254.041464 \nL 387.08487 254.202058 \nL 387.898133 253.387804 \nL 388.711396 253.948104 \nL 390.337922 254.071931 \nL 392.777711 254.164924 \nL 393.590973 254.320696 \nL 394.404236 254.121029 \nL 397.657288 254.376363 \nL 399.283814 254.240097 \nL 400.097077 254.349033 \nL 400.910339 254.242075 \nL 404.163391 254.456501 \nL 405.789917 254.413538 \nL 406.60318 254.524131 \nL 408.229705 254.461534 \nL 409.042968 254.599265 \nL 411.482757 254.368123 \nL 412.29602 254.525696 \nL 413.109283 254.44846 \nL 416.362334 254.647816 \nL 417.175597 254.449756 \nL 417.98886 254.513756 \nL 418.802123 254.430538 \nL 420.428649 254.62778 \nL 422.055175 254.581349 \nL 422.868437 254.668153 \nL 423.6817 254.530777 \nL 425.308226 254.689603 \nL 426.121489 254.828644 \nL 426.934752 254.482359 \nL 427.748015 254.661918 \nL 428.561278 254.622312 \nL 429.374541 254.871195 \nL 431.001066 254.597337 \nL 431.814329 254.656855 \nL 432.627592 254.907257 \nL 433.440855 254.966077 \nL 435.067381 254.801399 \nL 435.880644 254.918596 \nL 438.320432 254.93513 \nL 440.760221 254.948925 \nL 444.826535 254.945021 \nL 445.639798 255.14402 \nL 448.079587 254.97953 \nL 448.89285 255.054459 \nL 449.706113 255.007095 \nL 451.332639 255.052833 \nL 453.772427 255.22661 \nL 454.58569 255.07361 \nL 455.398953 255.146138 \nL 456.212216 255.076563 \nL 456.212216 255.076563 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#p97718cc0d7)\" d=\"M 50.394034 277.289043 \nL 51.207297 263.937464 \nL 52.02056 254.082729 \nL 53.647086 209.577465 \nL 54.460349 201.630095 \nL 55.273611 195.802022 \nL 56.086874 193.470797 \nL 56.900137 185.417466 \nL 57.7134 184.675708 \nL 58.526663 172.383782 \nL 60.153189 161.363428 \nL 60.966452 163.694661 \nL 61.779715 159.985887 \nL 62.592977 158.714307 \nL 64.219503 154.793605 \nL 65.032766 153.627993 \nL 65.846029 150.660977 \nL 66.659292 149.389396 \nL 67.472555 150.449041 \nL 68.285818 148.859573 \nL 69.099081 145.68063 \nL 69.912343 144.197114 \nL 70.725606 144.726937 \nL 71.538869 142.501679 \nL 72.352132 145.786582 \nL 73.165395 145.574662 \nL 73.978658 142.819566 \nL 74.791921 140.594308 \nL 75.605184 139.534663 \nL 76.418447 141.759921 \nL 78.044972 143.349388 \nL 78.858235 140.806243 \nL 79.671498 139.21676 \nL 80.484761 138.36905 \nL 81.298024 140.806243 \nL 82.111287 138.157114 \nL 82.92455 138.475001 \nL 83.737813 138.263082 \nL 84.551075 139.21676 \nL 85.364338 136.355711 \nL 86.177601 136.567647 \nL 86.990864 135.931857 \nL 87.804127 137.839211 \nL 88.61739 135.719921 \nL 89.430653 136.037808 \nL 90.243916 135.296066 \nL 91.057179 137.945179 \nL 91.870441 136.249744 \nL 92.683704 137.097469 \nL 93.496967 134.44834 \nL 94.31023 133.706582 \nL 95.123493 136.249744 \nL 95.936756 133.17676 \nL 96.750019 131.905179 \nL 97.563282 134.342373 \nL 98.376545 132.32905 \nL 99.189807 134.766244 \nL 100.00307 134.130453 \nL 100.816333 133.282728 \nL 101.629596 133.070792 \nL 102.442859 134.342373 \nL 103.256122 131.69326 \nL 104.069385 134.342373 \nL 104.882648 129.467986 \nL 105.695911 131.799212 \nL 106.509173 131.163421 \nL 107.322436 131.587292 \nL 108.135699 131.587292 \nL 108.948962 130.209744 \nL 109.762225 128.408341 \nL 111.388751 131.905179 \nL 112.202014 130.527647 \nL 113.015277 127.666583 \nL 113.828539 132.117115 \nL 114.641802 132.223083 \nL 115.455065 129.044131 \nL 116.268328 128.938163 \nL 117.081591 130.951502 \nL 117.894854 130.315712 \nL 118.708117 131.163421 \nL 119.52138 129.891857 \nL 120.334643 126.712905 \nL 121.147905 128.620276 \nL 121.961168 128.302373 \nL 123.587694 127.13676 \nL 124.400957 130.315712 \nL 125.21422 132.117115 \nL 126.027483 129.997808 \nL 126.840746 127.030792 \nL 127.654009 125.441325 \nL 128.467271 126.50097 \nL 129.280534 129.150099 \nL 130.093797 126.712905 \nL 130.90706 126.712905 \nL 131.720323 123.427986 \nL 132.533586 128.726244 \nL 133.346849 126.712905 \nL 134.160112 126.50097 \nL 134.973375 127.878518 \nL 135.786637 125.01747 \nL 136.5999 125.86518 \nL 137.413163 125.65326 \nL 138.226426 126.924825 \nL 139.039689 123.957809 \nL 139.852952 126.395002 \nL 140.666215 125.229389 \nL 141.479478 125.01747 \nL 142.292741 124.275712 \nL 143.106003 124.911502 \nL 143.919266 125.123422 \nL 144.732529 123.004131 \nL 145.545792 125.86518 \nL 146.359055 126.924825 \nL 147.172318 125.229389 \nL 147.985581 125.01747 \nL 148.798844 125.335357 \nL 149.612107 124.275712 \nL 150.425369 124.275712 \nL 151.238632 122.898164 \nL 152.865158 126.395002 \nL 153.678421 125.335357 \nL 154.491684 123.533954 \nL 155.304947 126.395002 \nL 156.11821 125.123422 \nL 156.931473 125.547293 \nL 157.744735 124.169744 \nL 158.557998 125.229389 \nL 159.371261 125.335357 \nL 160.184524 127.454663 \nL 160.997787 123.639922 \nL 161.81105 122.792196 \nL 162.624313 124.169744 \nL 163.437576 123.639922 \nL 164.250839 125.65326 \nL 165.064101 122.686228 \nL 165.877364 123.533954 \nL 166.690627 125.229389 \nL 167.50389 123.533954 \nL 168.317153 120.990793 \nL 169.130416 126.183083 \nL 169.943679 120.037116 \nL 170.756942 121.520615 \nL 171.570205 123.533954 \nL 172.383468 123.216067 \nL 173.19673 123.110099 \nL 174.009993 121.732551 \nL 174.823256 119.82518 \nL 175.636519 120.990793 \nL 176.449782 122.474309 \nL 177.263045 120.884825 \nL 178.076308 124.699567 \nL 178.889571 121.732551 \nL 179.702834 122.262373 \nL 180.516096 120.672906 \nL 181.329359 123.745889 \nL 182.142622 124.487648 \nL 182.955885 121.308696 \nL 183.769148 119.507293 \nL 184.582411 119.401325 \nL 185.395674 122.368341 \nL 186.208937 122.156406 \nL 187.0222 122.368341 \nL 187.835462 120.249051 \nL 188.648725 121.732551 \nL 189.461988 119.82518 \nL 190.275251 121.838519 \nL 191.088514 120.990793 \nL 191.901777 121.520615 \nL 192.71504 121.096761 \nL 193.528303 121.096761 \nL 194.341566 120.672906 \nL 195.154828 121.414664 \nL 195.968091 122.368341 \nL 196.781354 119.931148 \nL 197.594617 119.295357 \nL 198.40788 122.792196 \nL 200.034406 121.096761 \nL 200.847669 119.719212 \nL 201.660932 122.898164 \nL 202.474194 120.46097 \nL 203.287457 121.944486 \nL 204.10072 120.672906 \nL 204.913983 122.474309 \nL 205.727246 120.46097 \nL 207.353772 120.566938 \nL 208.167035 120.355003 \nL 208.980298 121.308696 \nL 209.79356 121.414664 \nL 210.606823 120.46097 \nL 211.420086 120.143083 \nL 212.233349 122.050454 \nL 213.046612 120.672906 \nL 213.859875 120.566938 \nL 214.673138 121.414664 \nL 215.486401 120.778874 \nL 216.299664 119.18939 \nL 217.112926 118.871503 \nL 217.926189 118.97747 \nL 218.739452 119.401325 \nL 219.552715 117.176067 \nL 220.365978 121.520615 \nL 221.179241 120.46097 \nL 221.992504 120.46097 \nL 222.805767 120.143083 \nL 223.61903 120.249051 \nL 224.432292 118.97747 \nL 225.245555 120.46097 \nL 226.058818 124.169744 \nL 226.872081 120.249051 \nL 227.685344 118.235712 \nL 228.498607 118.129745 \nL 229.31187 119.613261 \nL 230.125133 117.70589 \nL 230.938396 119.719212 \nL 231.751658 120.037116 \nL 232.564921 119.719212 \nL 233.378184 119.82518 \nL 234.191447 121.520615 \nL 235.00471 120.46097 \nL 235.817973 118.871503 \nL 236.631236 120.143083 \nL 237.444499 118.97747 \nL 238.257762 118.659567 \nL 239.071024 116.752196 \nL 239.884287 122.580277 \nL 240.69755 119.401325 \nL 241.510813 117.917809 \nL 242.324076 119.295357 \nL 243.137339 119.083422 \nL 243.950602 119.719212 \nL 244.763865 117.70589 \nL 245.577128 117.176067 \nL 246.39039 118.765535 \nL 247.203653 122.050454 \nL 248.016916 116.540277 \nL 248.830179 116.328342 \nL 249.643442 118.765535 \nL 250.456705 117.70589 \nL 251.269968 117.0701 \nL 252.083231 117.387987 \nL 252.896494 116.222374 \nL 253.709756 118.447648 \nL 255.336282 120.249051 \nL 256.149545 117.811858 \nL 256.962808 119.401325 \nL 257.776071 116.858164 \nL 258.589334 117.176067 \nL 259.402597 116.222374 \nL 260.21586 117.176067 \nL 261.029122 115.904487 \nL 261.842385 118.129745 \nL 262.655648 119.507293 \nL 263.468911 115.798519 \nL 264.282174 118.553599 \nL 265.095437 118.235712 \nL 265.9087 119.931148 \nL 266.721963 116.752196 \nL 267.535226 118.34168 \nL 268.348488 116.540277 \nL 269.161751 118.129745 \nL 269.975014 118.97747 \nL 270.788277 118.34168 \nL 271.60154 119.401325 \nL 272.414803 114.209051 \nL 273.228066 117.811858 \nL 274.041329 117.70589 \nL 274.854592 116.858164 \nL 275.667854 119.083422 \nL 276.481117 118.765535 \nL 277.29438 118.871503 \nL 278.107643 117.811858 \nL 278.920906 115.798519 \nL 279.734169 116.752196 \nL 280.547432 118.34168 \nL 281.360695 116.116406 \nL 282.173958 118.34168 \nL 282.98722 114.632906 \nL 283.800483 116.328342 \nL 284.613746 115.374664 \nL 285.427009 118.765535 \nL 286.240272 115.268696 \nL 287.053535 117.917809 \nL 287.866798 117.0701 \nL 288.680061 115.904487 \nL 289.493324 117.282019 \nL 290.306586 114.632906 \nL 291.119849 118.447648 \nL 291.933112 118.34168 \nL 293.559638 115.162729 \nL 294.372901 117.282019 \nL 295.186164 116.010454 \nL 295.999427 115.904487 \nL 296.81269 114.738874 \nL 297.625952 117.599922 \nL 298.439215 116.328342 \nL 299.252478 116.010454 \nL 300.065741 117.176067 \nL 300.879004 117.282019 \nL 301.692267 118.023777 \nL 302.50553 119.82518 \nL 303.318793 113.255358 \nL 304.132056 117.493954 \nL 304.945318 116.964132 \nL 305.758581 117.70589 \nL 306.571844 115.162729 \nL 307.385107 116.116406 \nL 308.19837 116.540277 \nL 309.011633 117.917809 \nL 309.824896 116.964132 \nL 310.638159 114.526938 \nL 311.451422 115.268696 \nL 312.264684 113.255358 \nL 313.077947 116.752196 \nL 313.89121 112.407632 \nL 314.704473 117.387987 \nL 315.517736 115.268696 \nL 316.330999 116.858164 \nL 317.144262 116.222374 \nL 317.957525 114.315003 \nL 318.770788 116.540277 \nL 319.58405 116.222374 \nL 320.397313 115.268696 \nL 321.210576 116.328342 \nL 322.023839 116.646229 \nL 322.837102 116.646229 \nL 323.650365 115.268696 \nL 324.463628 116.010454 \nL 325.276891 115.904487 \nL 326.090154 117.493954 \nL 326.903416 112.407632 \nL 327.716679 113.255358 \nL 328.529942 116.646229 \nL 329.343205 116.010454 \nL 330.969731 113.573261 \nL 331.782994 117.493954 \nL 332.596257 114.526938 \nL 333.40952 115.162729 \nL 334.222782 116.116406 \nL 335.036045 114.526938 \nL 335.849308 113.255358 \nL 336.662571 118.235712 \nL 337.475834 113.997116 \nL 338.289097 114.738874 \nL 339.10236 115.268696 \nL 339.915623 114.632906 \nL 340.728886 113.78518 \nL 341.542149 115.374664 \nL 342.355411 114.315003 \nL 343.168674 116.540277 \nL 343.981937 116.116406 \nL 344.7952 114.209051 \nL 345.608463 111.347987 \nL 346.421726 112.5136 \nL 347.234989 115.480616 \nL 348.048252 115.056761 \nL 348.861515 114.950793 \nL 349.674777 116.116406 \nL 350.48804 113.78518 \nL 351.301303 114.738874 \nL 352.114566 115.056761 \nL 352.927829 114.315003 \nL 353.741092 115.374664 \nL 354.554355 114.738874 \nL 355.367618 115.586583 \nL 356.180881 113.573261 \nL 356.994143 111.983777 \nL 357.807406 114.632906 \nL 358.620669 116.116406 \nL 359.433932 114.315003 \nL 360.247195 113.679213 \nL 361.060458 114.632906 \nL 361.873721 114.844825 \nL 362.686984 113.255358 \nL 363.500247 113.14939 \nL 364.313509 115.162729 \nL 365.126772 115.586583 \nL 366.753298 114.420971 \nL 367.566561 113.679213 \nL 368.379824 112.725535 \nL 369.193087 115.374664 \nL 370.00635 112.407632 \nL 371.632875 112.831503 \nL 372.446138 112.089745 \nL 374.072664 114.950793 \nL 374.885927 112.937471 \nL 375.69919 113.573261 \nL 376.512453 114.632906 \nL 377.325716 113.467293 \nL 378.138979 115.056761 \nL 378.952241 112.937471 \nL 379.765504 114.738874 \nL 380.578767 116.964132 \nL 381.39203 115.480616 \nL 382.205293 114.632906 \nL 383.018556 114.103084 \nL 383.831819 111.0301 \nL 384.645082 114.950793 \nL 385.458345 113.78518 \nL 387.08487 112.301681 \nL 387.898133 112.831503 \nL 388.711396 115.268696 \nL 389.524659 112.937471 \nL 390.337922 111.559922 \nL 391.151185 113.997116 \nL 391.964448 111.87781 \nL 392.777711 116.328342 \nL 393.590973 114.632906 \nL 394.404236 112.301681 \nL 395.217499 111.242019 \nL 396.030762 112.831503 \nL 396.844025 113.361326 \nL 397.657288 115.374664 \nL 398.470551 113.361326 \nL 399.283814 112.089745 \nL 400.097077 113.467293 \nL 400.910339 114.420971 \nL 401.723602 112.301681 \nL 402.536865 114.420971 \nL 403.350128 115.268696 \nL 404.163391 113.14939 \nL 404.976654 113.361326 \nL 405.789917 114.844825 \nL 406.60318 114.738874 \nL 407.416443 111.983777 \nL 409.042968 111.87781 \nL 409.856231 114.103084 \nL 410.669494 112.407632 \nL 411.482757 113.997116 \nL 412.29602 114.632906 \nL 414.735809 111.983777 \nL 415.549071 112.5136 \nL 416.362334 112.5136 \nL 417.175597 111.242019 \nL 417.98886 111.453955 \nL 418.802123 114.738874 \nL 419.615386 111.87781 \nL 420.428649 111.559922 \nL 421.241912 113.573261 \nL 422.055175 112.407632 \nL 422.868437 113.679213 \nL 423.6817 113.78518 \nL 424.494963 112.937471 \nL 425.308226 111.87781 \nL 426.121489 114.315003 \nL 426.934752 112.937471 \nL 427.748015 110.288342 \nL 428.561278 113.891148 \nL 430.187803 116.646229 \nL 431.001066 114.526938 \nL 431.814329 111.242019 \nL 432.627592 113.679213 \nL 433.440855 115.056761 \nL 434.254118 110.712197 \nL 435.067381 114.632906 \nL 435.880644 113.997116 \nL 436.693907 111.983777 \nL 437.507169 115.056761 \nL 438.320432 111.242019 \nL 439.133695 114.103084 \nL 439.946958 112.831503 \nL 440.760221 109.864487 \nL 442.386747 111.347987 \nL 443.20001 113.679213 \nL 444.013273 110.606229 \nL 444.826535 113.043422 \nL 445.639798 112.195713 \nL 446.453061 113.467293 \nL 447.266324 110.182374 \nL 448.079587 111.87781 \nL 448.89285 110.818164 \nL 449.706113 113.679213 \nL 450.519376 110.39431 \nL 452.145901 111.87781 \nL 452.959164 111.983777 \nL 453.772427 109.440616 \nL 454.58569 111.559922 \nL 455.398953 110.39431 \nL 456.212216 114.209051 \nL 456.212216 114.209051 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p97718cc0d7)\" d=\"M 51.03941 -1 \nL 51.207297 47.470204 \nL 52.02056 147.032776 \nL 52.833823 165.793126 \nL 53.647086 176.397847 \nL 54.460349 184.281752 \nL 56.086874 195.429005 \nL 57.7134 203.968157 \nL 59.339926 208.887784 \nL 60.153189 211.216976 \nL 60.966452 212.962609 \nL 63.40624 216.666612 \nL 64.219503 217.347452 \nL 65.846029 219.022292 \nL 68.285818 220.859729 \nL 69.099081 221.136252 \nL 69.912343 221.614675 \nL 70.725606 221.79056 \nL 71.538869 222.706393 \nL 73.978658 223.631569 \nL 76.418447 224.928119 \nL 78.044972 225.578137 \nL 79.671498 226.199485 \nL 80.484761 226.344901 \nL 84.551075 227.633484 \nL 86.177601 228.213787 \nL 86.990864 228.571852 \nL 87.804127 228.697738 \nL 91.057179 229.633105 \nL 92.683704 229.90254 \nL 93.496967 230.263557 \nL 94.31023 230.307262 \nL 95.123493 230.63156 \nL 95.936756 230.78696 \nL 96.750019 231.105098 \nL 98.376545 231.166847 \nL 100.00307 231.531808 \nL 101.629596 231.91681 \nL 102.442859 231.952585 \nL 103.256122 232.187517 \nL 104.069385 232.193763 \nL 104.882648 232.489281 \nL 107.322436 232.694906 \nL 108.135699 232.579943 \nL 108.948962 232.716615 \nL 109.762225 233.052598 \nL 111.388751 233.221999 \nL 112.202014 233.08171 \nL 113.015277 232.758445 \nL 113.828539 233.047154 \nL 116.268328 233.388783 \nL 117.081591 233.622027 \nL 120.334643 233.844829 \nL 121.147905 233.69418 \nL 122.774431 233.750521 \nL 125.21422 233.978678 \nL 126.027483 234.020856 \nL 126.840746 233.866169 \nL 128.467271 233.908229 \nL 129.280534 233.732445 \nL 132.533586 233.95818 \nL 133.346849 233.771748 \nL 134.160112 234.026254 \nL 135.786637 234.032763 \nL 138.226426 234.214719 \nL 139.039689 233.82879 \nL 139.852952 234.197118 \nL 140.666215 234.276237 \nL 146.359055 233.967714 \nL 147.172318 234.299513 \nL 148.798844 234.155932 \nL 149.612107 234.253957 \nL 150.425369 233.673216 \nL 151.238632 234.132295 \nL 152.051895 233.764956 \nL 153.678421 234.008689 \nL 154.491684 234.141578 \nL 155.304947 233.948727 \nL 156.11821 233.917314 \nL 156.931473 234.071486 \nL 160.997787 234.114333 \nL 161.81105 234.082827 \nL 162.624313 234.403585 \nL 165.877364 234.114977 \nL 166.690627 233.767925 \nL 167.50389 233.849867 \nL 168.317153 234.092551 \nL 169.130416 234.003999 \nL 169.943679 234.05286 \nL 170.756942 233.954049 \nL 171.570205 234.150711 \nL 174.009993 233.83431 \nL 174.823256 234.10456 \nL 177.263045 233.830515 \nL 179.702834 233.908375 \nL 180.516096 234.150513 \nL 182.142622 233.984603 \nL 182.955885 234.124179 \nL 183.769148 233.515245 \nL 184.582411 233.743276 \nL 186.208937 233.867631 \nL 187.0222 234.090858 \nL 188.648725 233.964344 \nL 189.461988 233.538371 \nL 190.275251 233.824655 \nL 191.088514 233.599966 \nL 191.901777 233.811905 \nL 192.71504 233.452407 \nL 194.341566 234.019576 \nL 195.154828 233.616543 \nL 195.968091 233.663026 \nL 198.40788 233.394154 \nL 200.034406 233.636554 \nL 202.474194 233.764924 \nL 203.287457 233.720246 \nL 204.10072 233.532284 \nL 205.727246 233.36379 \nL 206.540509 233.610743 \nL 207.353772 233.601513 \nL 208.167035 233.709457 \nL 208.980298 233.537909 \nL 210.606823 233.856286 \nL 211.420086 233.510364 \nL 213.046612 233.597851 \nL 214.673138 233.565612 \nL 216.299664 233.774688 \nL 217.112926 233.090183 \nL 218.739452 233.779054 \nL 219.552715 233.960521 \nL 220.365978 233.349691 \nL 221.179241 233.491353 \nL 221.992504 233.482467 \nL 222.805767 233.21777 \nL 223.61903 233.386232 \nL 226.058818 233.297684 \nL 227.685344 233.574681 \nL 228.498607 233.365345 \nL 229.31187 233.005936 \nL 230.125133 233.234886 \nL 230.938396 233.200703 \nL 231.751658 232.775714 \nL 232.564921 233.073359 \nL 233.378184 232.995118 \nL 234.191447 233.274752 \nL 235.817973 233.120134 \nL 236.631236 233.177225 \nL 237.444499 233.027758 \nL 238.257762 233.305387 \nL 239.071024 233.067255 \nL 239.884287 233.348039 \nL 240.69755 233.094432 \nL 241.510813 233.05033 \nL 242.324076 233.170647 \nL 243.137339 233.089819 \nL 244.763865 233.277068 \nL 246.39039 233.045984 \nL 247.203653 232.748781 \nL 248.016916 232.96277 \nL 249.643442 232.82074 \nL 250.456705 232.933386 \nL 251.269968 232.667304 \nL 252.896494 233.153985 \nL 253.709756 232.966865 \nL 254.523019 233.051059 \nL 255.336282 232.793798 \nL 256.149545 232.947238 \nL 256.962808 232.827175 \nL 257.776071 232.969141 \nL 259.402597 232.477191 \nL 260.21586 232.881237 \nL 261.029122 232.906935 \nL 261.842385 232.080278 \nL 262.655648 232.732507 \nL 263.468911 232.451149 \nL 264.282174 232.922718 \nL 265.9087 232.654137 \nL 266.721963 233.085043 \nL 267.535226 232.855502 \nL 268.348488 232.816475 \nL 269.161751 232.600655 \nL 269.975014 232.89542 \nL 270.788277 232.924103 \nL 271.60154 232.448848 \nL 272.414803 232.872051 \nL 273.228066 232.510163 \nL 275.667854 232.399598 \nL 277.29438 232.408075 \nL 278.107643 232.271201 \nL 279.734169 232.585682 \nL 280.547432 232.450849 \nL 281.360695 232.821505 \nL 282.173958 232.644632 \nL 283.800483 232.666041 \nL 284.613746 232.772045 \nL 287.053535 232.237423 \nL 287.866798 232.790356 \nL 288.680061 232.725533 \nL 289.493324 232.889491 \nL 290.306586 232.79816 \nL 291.119849 232.930069 \nL 291.933112 232.68941 \nL 292.746375 232.807139 \nL 293.559638 232.47404 \nL 294.372901 232.562556 \nL 296.81269 232.441461 \nL 297.625952 232.226662 \nL 298.439215 232.41413 \nL 299.252478 232.466588 \nL 300.065741 232.398238 \nL 301.692267 232.116636 \nL 302.50553 232.66598 \nL 303.318793 232.26982 \nL 304.132056 232.095215 \nL 305.758581 231.920297 \nL 307.385107 232.291642 \nL 309.824896 232.141722 \nL 311.451422 232.40554 \nL 312.264684 232.285996 \nL 313.077947 232.291913 \nL 313.89121 232.491443 \nL 316.330999 232.058727 \nL 317.144262 231.986501 \nL 317.957525 232.193568 \nL 318.770788 232.238116 \nL 319.58405 232.093821 \nL 320.397313 232.281497 \nL 321.210576 232.04876 \nL 322.023839 232.39844 \nL 322.837102 232.137206 \nL 324.463628 232.156752 \nL 325.276891 231.734186 \nL 327.716679 232.338555 \nL 330.156468 231.663989 \nL 330.969731 231.680525 \nL 331.782994 232.084781 \nL 332.596257 231.845135 \nL 333.40952 231.764306 \nL 334.222782 231.947466 \nL 335.036045 231.521225 \nL 335.849308 231.927928 \nL 336.662571 231.782617 \nL 337.475834 231.282506 \nL 338.289097 231.502356 \nL 339.10236 232.105684 \nL 339.915623 231.757085 \nL 340.728886 231.866556 \nL 341.542149 231.669428 \nL 342.355411 231.79397 \nL 343.168674 231.758073 \nL 343.981937 231.569438 \nL 344.7952 232.058314 \nL 345.608463 231.77934 \nL 346.421726 232.00337 \nL 347.234989 231.960446 \nL 348.048252 231.521497 \nL 348.861515 231.856516 \nL 349.674777 231.919224 \nL 351.301303 231.532477 \nL 352.927829 231.88558 \nL 353.741092 231.97689 \nL 354.554355 231.665353 \nL 355.367618 231.619113 \nL 356.180881 232.041599 \nL 356.994143 231.727001 \nL 357.807406 231.920135 \nL 358.620669 231.742922 \nL 359.433932 231.99919 \nL 360.247195 231.496349 \nL 361.060458 231.646508 \nL 361.873721 231.618429 \nL 362.686984 231.709216 \nL 363.500247 231.543124 \nL 364.313509 231.610596 \nL 365.126772 231.414119 \nL 365.940035 231.68415 \nL 367.566561 231.672413 \nL 368.379824 231.86251 \nL 369.193087 231.85537 \nL 370.00635 231.472802 \nL 370.819613 231.622414 \nL 372.446138 231.447221 \nL 373.259401 231.640028 \nL 374.072664 231.640559 \nL 375.69919 231.402313 \nL 376.512453 231.31596 \nL 377.325716 231.685227 \nL 378.952241 231.414597 \nL 380.578767 231.303745 \nL 382.205293 231.473114 \nL 383.018556 231.417825 \nL 383.831819 231.68078 \nL 384.645082 231.724878 \nL 386.271607 231.451126 \nL 387.08487 231.500711 \nL 387.898133 232.007148 \nL 388.711396 231.780705 \nL 389.524659 231.395979 \nL 390.337922 231.761427 \nL 391.151185 231.569066 \nL 393.590973 231.732582 \nL 394.404236 231.380746 \nL 395.217499 231.404731 \nL 396.030762 231.596129 \nL 396.844025 231.433593 \nL 397.657288 231.486819 \nL 398.470551 231.167896 \nL 399.283814 231.176664 \nL 400.097077 231.407165 \nL 400.910339 231.166737 \nL 401.723602 231.207206 \nL 402.536865 231.096496 \nL 403.350128 231.166778 \nL 404.163391 231.392593 \nL 404.976654 231.196805 \nL 406.60318 231.572006 \nL 408.229705 231.331233 \nL 409.042968 231.536855 \nL 409.856231 231.116734 \nL 410.669494 231.244654 \nL 411.482757 231.050677 \nL 412.29602 231.223318 \nL 413.922546 230.924843 \nL 415.549071 230.944024 \nL 416.362334 231.059725 \nL 417.175597 230.919007 \nL 418.802123 231.338896 \nL 419.615386 231.134445 \nL 422.868437 231.234144 \nL 423.6817 231.153846 \nL 424.494963 231.289926 \nL 425.308226 231.25838 \nL 426.121489 230.855598 \nL 426.934752 230.888776 \nL 427.748015 230.688359 \nL 428.561278 231.047173 \nL 430.187803 231.018604 \nL 431.001066 231.049324 \nL 431.814329 231.214181 \nL 432.627592 231.185603 \nL 433.440855 230.937925 \nL 434.254118 231.007267 \nL 435.067381 230.66693 \nL 435.880644 230.935661 \nL 436.693907 230.972922 \nL 437.507169 230.744462 \nL 438.320432 230.854954 \nL 439.946958 230.793967 \nL 440.760221 230.926831 \nL 441.573484 230.698999 \nL 442.386747 230.854622 \nL 443.20001 230.431638 \nL 444.013273 231.006392 \nL 446.453061 230.850381 \nL 448.079587 230.489538 \nL 449.706113 230.87646 \nL 450.519376 231.149358 \nL 451.332639 230.537455 \nL 452.145901 231.053629 \nL 453.772427 230.438413 \nL 454.58569 231.235889 \nL 456.212216 230.757556 \nL 456.212216 230.757556 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p97718cc0d7)\" d=\"M 50.394034 270.719218 \nL 51.207297 250.585886 \nL 52.02056 248.572551 \nL 52.833823 206.292554 \nL 53.647086 184.145886 \nL 54.460349 170.052556 \nL 55.273611 159.985887 \nL 56.086874 157.972549 \nL 56.900137 147.905888 \nL 57.7134 147.905888 \nL 58.526663 143.879211 \nL 60.153189 131.799212 \nL 60.966452 133.81255 \nL 61.779715 125.759212 \nL 62.592977 125.759212 \nL 63.40624 121.732551 \nL 64.219503 123.745889 \nL 65.032766 127.772551 \nL 65.846029 129.785889 \nL 66.659292 127.772551 \nL 67.472555 127.772551 \nL 68.285818 131.799212 \nL 69.912343 127.772551 \nL 70.725606 127.772551 \nL 71.538869 129.785889 \nL 73.165395 129.785889 \nL 73.978658 131.799212 \nL 74.791921 129.785889 \nL 75.605184 133.81255 \nL 76.418447 131.799212 \nL 77.231709 133.81255 \nL 78.044972 133.81255 \nL 78.858235 129.785889 \nL 79.671498 131.799212 \nL 80.484761 129.785889 \nL 81.298024 131.799212 \nL 86.990864 131.799212 \nL 87.804127 133.81255 \nL 89.430653 129.785889 \nL 100.816333 129.785889 \nL 101.629596 127.772551 \nL 103.256122 127.772551 \nL 104.069385 129.785889 \nL 104.882648 127.772551 \nL 109.762225 127.772551 \nL 110.575488 129.785889 \nL 111.388751 125.759212 \nL 112.202014 125.759212 \nL 113.015277 127.772551 \nL 114.641802 127.772551 \nL 115.455065 125.759212 \nL 116.268328 127.772551 \nL 119.52138 127.772551 \nL 120.334643 123.745889 \nL 121.147905 127.772551 \nL 121.961168 125.759212 \nL 122.774431 125.759212 \nL 123.587694 127.772551 \nL 124.400957 125.759212 \nL 125.21422 127.772551 \nL 126.027483 127.772551 \nL 126.840746 125.759212 \nL 127.654009 125.759212 \nL 128.467271 127.772551 \nL 129.280534 127.772551 \nL 130.093797 125.759212 \nL 140.666215 125.759212 \nL 141.479478 127.772551 \nL 142.292741 127.772551 \nL 143.106003 129.785889 \nL 143.919266 129.785889 \nL 144.732529 125.759212 \nL 145.545792 129.785889 \nL 149.612107 129.785889 \nL 150.425369 127.772551 \nL 151.238632 129.785889 \nL 152.051895 127.772551 \nL 160.184524 127.772551 \nL 160.997787 129.785889 \nL 161.81105 127.772551 \nL 162.624313 127.772551 \nL 163.437576 129.785889 \nL 164.250839 127.772551 \nL 165.064101 129.785889 \nL 169.943679 129.785889 \nL 170.756942 127.772551 \nL 171.570205 129.785889 \nL 172.383468 129.785889 \nL 173.19673 131.799212 \nL 174.009993 129.785889 \nL 174.823256 129.785889 \nL 175.636519 131.799212 \nL 176.449782 129.785889 \nL 177.263045 129.785889 \nL 178.076308 133.81255 \nL 178.889571 133.81255 \nL 179.702834 131.799212 \nL 181.329359 131.799212 \nL 182.142622 129.785889 \nL 182.955885 129.785889 \nL 183.769148 131.799212 \nL 184.582411 129.785889 \nL 185.395674 129.785889 \nL 186.208937 133.81255 \nL 187.0222 131.799212 \nL 187.835462 133.81255 \nL 188.648725 131.799212 \nL 189.461988 133.81255 \nL 190.275251 133.81255 \nL 191.088514 131.799212 \nL 191.901777 131.799212 \nL 192.71504 133.81255 \nL 193.528303 129.785889 \nL 194.341566 131.799212 \nL 195.968091 131.799212 \nL 196.781354 129.785889 \nL 197.594617 133.81255 \nL 198.40788 133.81255 \nL 199.221143 127.772551 \nL 200.034406 131.799212 \nL 200.847669 131.799212 \nL 201.660932 129.785889 \nL 202.474194 131.799212 \nL 203.287457 131.799212 \nL 204.10072 129.785889 \nL 205.727246 133.81255 \nL 207.353772 129.785889 \nL 208.167035 131.799212 \nL 208.980298 131.799212 \nL 209.79356 129.785889 \nL 210.606823 131.799212 \nL 213.046612 131.799212 \nL 213.859875 133.81255 \nL 214.673138 133.81255 \nL 215.486401 131.799212 \nL 216.299664 131.799212 \nL 217.112926 133.81255 \nL 217.926189 131.799212 \nL 218.739452 131.799212 \nL 219.552715 129.785889 \nL 220.365978 131.799212 \nL 221.179241 131.799212 \nL 221.992504 135.825889 \nL 222.805767 133.81255 \nL 223.61903 129.785889 \nL 224.432292 131.799212 \nL 226.058818 131.799212 \nL 226.872081 129.785889 \nL 227.685344 131.799212 \nL 228.498607 131.799212 \nL 229.31187 129.785889 \nL 230.125133 129.785889 \nL 230.938396 133.81255 \nL 232.564921 129.785889 \nL 233.378184 133.81255 \nL 235.817973 127.772551 \nL 236.631236 131.799212 \nL 237.444499 133.81255 \nL 238.257762 127.772551 \nL 239.071024 133.81255 \nL 241.510813 127.772551 \nL 242.324076 133.81255 \nL 243.137339 133.81255 \nL 243.950602 131.799212 \nL 246.39039 131.799212 \nL 247.203653 133.81255 \nL 248.016916 131.799212 \nL 250.456705 131.799212 \nL 251.269968 133.81255 \nL 252.083231 127.772551 \nL 252.896494 129.785889 \nL 253.709756 133.81255 \nL 254.523019 131.799212 \nL 256.149545 135.825889 \nL 257.776071 131.799212 \nL 258.589334 131.799212 \nL 259.402597 133.81255 \nL 260.21586 131.799212 \nL 261.029122 133.81255 \nL 261.842385 131.799212 \nL 262.655648 133.81255 \nL 263.468911 131.799212 \nL 264.282174 135.825889 \nL 265.9087 131.799212 \nL 266.721963 133.81255 \nL 267.535226 129.785889 \nL 268.348488 129.785889 \nL 269.975014 133.81255 \nL 270.788277 131.799212 \nL 271.60154 133.81255 \nL 272.414803 131.799212 \nL 273.228066 133.81255 \nL 274.041329 129.785889 \nL 274.854592 131.799212 \nL 278.107643 131.799212 \nL 278.920906 133.81255 \nL 279.734169 133.81255 \nL 280.547432 131.799212 \nL 281.360695 131.799212 \nL 282.173958 129.785889 \nL 282.98722 131.799212 \nL 283.800483 131.799212 \nL 284.613746 127.772551 \nL 287.053535 133.81255 \nL 288.680061 129.785889 \nL 291.119849 129.785889 \nL 292.746375 133.81255 \nL 293.559638 131.799212 \nL 294.372901 133.81255 \nL 295.999427 129.785889 \nL 296.81269 133.81255 \nL 297.625952 129.785889 \nL 298.439215 133.81255 \nL 299.252478 127.772551 \nL 300.879004 131.799212 \nL 302.50553 131.799212 \nL 303.318793 129.785889 \nL 306.571844 129.785889 \nL 307.385107 133.81255 \nL 308.19837 135.825889 \nL 309.824896 127.772551 \nL 310.638159 133.81255 \nL 311.451422 129.785889 \nL 312.264684 131.799212 \nL 313.077947 129.785889 \nL 315.517736 129.785889 \nL 316.330999 133.81255 \nL 317.144262 133.81255 \nL 317.957525 129.785889 \nL 318.770788 129.785889 \nL 320.397313 133.81255 \nL 322.023839 129.785889 \nL 322.837102 131.799212 \nL 323.650365 129.785889 \nL 326.090154 129.785889 \nL 326.903416 133.81255 \nL 327.716679 127.772551 \nL 328.529942 135.825889 \nL 329.343205 131.799212 \nL 330.156468 133.81255 \nL 330.969731 129.785889 \nL 331.782994 131.799212 \nL 332.596257 129.785889 \nL 333.40952 129.785889 \nL 334.222782 131.799212 \nL 336.662571 131.799212 \nL 337.475834 129.785889 \nL 338.289097 129.785889 \nL 339.10236 133.81255 \nL 339.915623 131.799212 \nL 340.728886 131.799212 \nL 341.542149 129.785889 \nL 342.355411 129.785889 \nL 343.168674 131.799212 \nL 343.981937 129.785889 \nL 344.7952 129.785889 \nL 345.608463 127.772551 \nL 346.421726 131.799212 \nL 347.234989 133.81255 \nL 348.048252 131.799212 \nL 348.861515 133.81255 \nL 352.114566 133.81255 \nL 352.927829 135.825889 \nL 353.741092 131.799212 \nL 354.554355 131.799212 \nL 355.367618 133.81255 \nL 356.180881 131.799212 \nL 360.247195 131.799212 \nL 361.060458 129.785889 \nL 361.873721 129.785889 \nL 362.686984 131.799212 \nL 363.500247 129.785889 \nL 364.313509 131.799212 \nL 365.940035 131.799212 \nL 366.753298 129.785889 \nL 367.566561 131.799212 \nL 368.379824 131.799212 \nL 369.193087 127.772551 \nL 370.00635 127.772551 \nL 370.819613 131.799212 \nL 371.632875 129.785889 \nL 372.446138 131.799212 \nL 373.259401 129.785889 \nL 374.885927 129.785889 \nL 375.69919 127.772551 \nL 376.512453 129.785889 \nL 378.138979 129.785889 \nL 379.765504 125.759212 \nL 380.578767 129.785889 \nL 387.08487 129.785889 \nL 387.898133 131.799212 \nL 388.711396 131.799212 \nL 389.524659 129.785889 \nL 390.337922 129.785889 \nL 391.151185 127.772551 \nL 391.964448 131.799212 \nL 393.590973 127.772551 \nL 394.404236 131.799212 \nL 395.217499 127.772551 \nL 396.030762 131.799212 \nL 396.844025 129.785889 \nL 397.657288 129.785889 \nL 398.470551 131.799212 \nL 399.283814 129.785889 \nL 400.910339 129.785889 \nL 401.723602 131.799212 \nL 402.536865 129.785889 \nL 405.789917 129.785889 \nL 406.60318 127.772551 \nL 407.416443 129.785889 \nL 408.229705 127.772551 \nL 409.042968 129.785889 \nL 410.669494 129.785889 \nL 411.482757 127.772551 \nL 413.109283 127.772551 \nL 413.922546 129.785889 \nL 414.735809 127.772551 \nL 419.615386 127.772551 \nL 420.428649 129.785889 \nL 421.241912 127.772551 \nL 422.055175 127.772551 \nL 422.868437 131.799212 \nL 423.6817 127.772551 \nL 424.494963 129.785889 \nL 425.308226 125.759212 \nL 426.934752 129.785889 \nL 427.748015 129.785889 \nL 428.561278 127.772551 \nL 431.001066 127.772551 \nL 431.814329 125.759212 \nL 432.627592 127.772551 \nL 433.440855 125.759212 \nL 434.254118 127.772551 \nL 435.880644 127.772551 \nL 436.693907 129.785889 \nL 437.507169 127.772551 \nL 438.320432 127.772551 \nL 439.133695 131.799212 \nL 440.760221 127.772551 \nL 441.573484 129.785889 \nL 444.013273 129.785889 \nL 444.826535 127.772551 \nL 445.639798 129.785889 \nL 446.453061 125.759212 \nL 447.266324 127.772551 \nL 448.079587 127.772551 \nL 448.89285 125.759212 \nL 454.58569 125.759212 \nL 455.398953 129.785889 \nL 456.212216 127.772551 \nL 456.212216 127.772551 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 282.799219 \nL 30.103125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 476.503125 282.799219 \nL 476.503125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 282.799219 \nL 476.503125 282.799219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.999219 \nL 476.503125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 372.559375 78.267969 \nL 469.503125 78.267969 \nQ 471.503125 78.267969 471.503125 76.267969 \nL 471.503125 17.999219 \nQ 471.503125 15.999219 469.503125 15.999219 \nL 372.559375 15.999219 \nQ 370.559375 15.999219 370.559375 17.999219 \nL 370.559375 76.267969 \nQ 370.559375 78.267969 372.559375 78.267969 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_29\">\n     <path d=\"M 374.559375 24.097656 \nL 394.559375 24.097656 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_30\"/>\n    <g id=\"text_13\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(402.559375 27.597656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 374.559375 38.775781 \nL 394.559375 38.775781 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_14\">\n     <!-- accuracy -->\n     <defs>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <g transform=\"translate(402.559375 42.275781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 374.559375 53.453906 \nL 394.559375 53.453906 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_15\">\n     <!-- val_loss -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n     </defs>\n     <g transform=\"translate(402.559375 56.953906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 374.559375 68.410156 \nL 394.559375 68.410156 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_36\"/>\n    <g id=\"text_16\">\n     <!-- val_accuracy -->\n     <g transform=\"translate(402.559375 71.910156)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"369.482422\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"432.861328\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"473.974609\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"535.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"590.234375\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p97718cc0d7\">\n   <rect height=\"271.8\" width=\"446.4\" x=\"30.103125\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.8576766456717055,)"
     },
     "metadata": {},
     "execution_count": 405
    }
   ],
   "source": [
    "Y_test_raw = np.hstack(y_test).flatten()\n",
    "Y_test_imputed = np.hstack(model.predict(X_test)).flatten()\n",
    "\n",
    "Y_test_imputed = Y_test_imputed[Y_test_raw>0]\n",
    "Y_test_raw = Y_test_raw[Y_test_raw>0]\n",
    "\n",
    "pearsonr(Y_test_raw,Y_test_imputed)[0],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trying Methods Besides Deep Neural Networks\n",
    "- Random Forrest?\n",
    "- Classification Trees?\n",
    "- Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_30933_100_index = pd.Series.nlargest(subMatrix.iloc[0,:], 100).index\n",
    "gene_30933_100_index = gene_30933_100_index.insert(loc=0, item=30933)  #Adding \"y\"\n",
    "\n",
    "gene_30933_100 = data_pred_unnorm.loc[:,gene_30933_100_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      y30933  26286  12570  29701  28881  29176  31196  22493  29827  12627  \\\n1       12.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n2       10.0    0.0    1.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0   \n3        8.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n4       78.0    3.0    0.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0   \n5       18.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n2696    88.0    3.0    0.0    0.0    4.0    0.0    0.0    0.0    1.0    1.0   \n2697    11.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    2.0    0.0   \n2698    10.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n2699     5.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n2700    11.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n\n      ...  7341  29988  11858  7188  15913  22465  20008  31213  23405  764  \n1     ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n2     ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n3     ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n4     ...   0.0    0.0    1.0   0.0    0.0    0.0    0.0    1.0    0.0  0.0  \n5     ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n...   ...   ...    ...    ...   ...    ...    ...    ...    ...    ...  ...  \n2696  ...   0.0    0.0    0.0   1.0    1.0    0.0    0.0    0.0    0.0  1.0  \n2697  ...   0.0    0.0    0.0   1.0    3.0    0.0    0.0    0.0    0.0  0.0  \n2698  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n2699  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n2700  ...   0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  0.0  \n\n[2700 rows x 101 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y30933</th>\n      <th>26286</th>\n      <th>12570</th>\n      <th>29701</th>\n      <th>28881</th>\n      <th>29176</th>\n      <th>31196</th>\n      <th>22493</th>\n      <th>29827</th>\n      <th>12627</th>\n      <th>...</th>\n      <th>7341</th>\n      <th>29988</th>\n      <th>11858</th>\n      <th>7188</th>\n      <th>15913</th>\n      <th>22465</th>\n      <th>20008</th>\n      <th>31213</th>\n      <th>23405</th>\n      <th>764</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>78.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>88.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2697</th>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2699</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2700</th>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2700 rows × 101 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 523
    }
   ],
   "source": [
    "gene_30933_100.index = list(range(1,2701))\n",
    "gene_30933_100.rename(columns={30933: 'y30933'}, inplace = True)\n",
    "gene_30933_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_30933_100.to_csv(\"/Users/ahmadazim/Documents/Research/imputeML/gene_30933_100.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             30933        18998        21053        1955         9798   \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000   \nmean      2.457839     2.349489     1.127563     0.738349     1.500419   \nstd       1.260208     1.134424     1.398795     1.256057     1.152750   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       1.609438     1.609438     0.000000     0.000000     0.693147   \n50%       2.079442     2.079442     0.693147     0.000000     1.098612   \n75%       3.441924     2.995732     1.386294     0.693147     2.397895   \nmax       5.971262     6.040255     5.257495     5.135798     5.455321   \n\n             10677        11887        13302        1957         28817  ...  \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000  ...   \nmean      1.057086     2.561134     3.672724     0.540868     0.777489  ...   \nstd       1.226931     0.837687     0.603685     1.042676     1.168722  ...   \nmin       0.000000     0.000000     0.693147     0.000000     0.000000  ...   \n25%       0.000000     2.079442     3.332205     0.000000     0.000000  ...   \n50%       0.693147     2.564949     3.688879     0.000000     0.000000  ...   \n75%       2.079442     3.091043     4.043051     0.693147     1.098612  ...   \nmax       5.476463     5.736572     5.953243     4.442651     4.836282  ...   \n\n             17597        113          12646        22162        4130   \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000   \nmean      0.307567     0.175108     0.212813     0.063072     0.458054   \nstd       0.434491     0.344565     0.380495     0.226848     0.519108   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.693147   \n75%       0.693147     0.000000     0.693147     0.000000     0.693147   \nmax       3.970292     3.850147     3.737670     3.988984     3.258096   \n\n             439          11940        30114        3517         29538  \ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000  \nmean      0.133351     0.079387     0.164015     0.169051     0.206075  \nstd       0.350104     0.247311     0.405440     0.339583     0.371577  \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n75%       0.000000     0.000000     0.000000     0.000000     0.693147  \nmax       3.891820     3.970292     3.610918     3.871201     3.688879  \n\n[8 rows x 512 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>30933</th>\n      <th>18998</th>\n      <th>21053</th>\n      <th>1955</th>\n      <th>9798</th>\n      <th>10677</th>\n      <th>11887</th>\n      <th>13302</th>\n      <th>1957</th>\n      <th>28817</th>\n      <th>...</th>\n      <th>17597</th>\n      <th>113</th>\n      <th>12646</th>\n      <th>22162</th>\n      <th>4130</th>\n      <th>439</th>\n      <th>11940</th>\n      <th>30114</th>\n      <th>3517</th>\n      <th>29538</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>...</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.457839</td>\n      <td>2.349489</td>\n      <td>1.127563</td>\n      <td>0.738349</td>\n      <td>1.500419</td>\n      <td>1.057086</td>\n      <td>2.561134</td>\n      <td>3.672724</td>\n      <td>0.540868</td>\n      <td>0.777489</td>\n      <td>...</td>\n      <td>0.307567</td>\n      <td>0.175108</td>\n      <td>0.212813</td>\n      <td>0.063072</td>\n      <td>0.458054</td>\n      <td>0.133351</td>\n      <td>0.079387</td>\n      <td>0.164015</td>\n      <td>0.169051</td>\n      <td>0.206075</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.260208</td>\n      <td>1.134424</td>\n      <td>1.398795</td>\n      <td>1.256057</td>\n      <td>1.152750</td>\n      <td>1.226931</td>\n      <td>0.837687</td>\n      <td>0.603685</td>\n      <td>1.042676</td>\n      <td>1.168722</td>\n      <td>...</td>\n      <td>0.434491</td>\n      <td>0.344565</td>\n      <td>0.380495</td>\n      <td>0.226848</td>\n      <td>0.519108</td>\n      <td>0.350104</td>\n      <td>0.247311</td>\n      <td>0.405440</td>\n      <td>0.339583</td>\n      <td>0.371577</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.609438</td>\n      <td>1.609438</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>2.079442</td>\n      <td>3.332205</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.079442</td>\n      <td>2.079442</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>1.098612</td>\n      <td>0.693147</td>\n      <td>2.564949</td>\n      <td>3.688879</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.441924</td>\n      <td>2.995732</td>\n      <td>1.386294</td>\n      <td>0.693147</td>\n      <td>2.397895</td>\n      <td>2.079442</td>\n      <td>3.091043</td>\n      <td>4.043051</td>\n      <td>0.693147</td>\n      <td>1.098612</td>\n      <td>...</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.693147</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.971262</td>\n      <td>6.040255</td>\n      <td>5.257495</td>\n      <td>5.135798</td>\n      <td>5.455321</td>\n      <td>5.476463</td>\n      <td>5.736572</td>\n      <td>5.953243</td>\n      <td>4.442651</td>\n      <td>4.836282</td>\n      <td>...</td>\n      <td>3.970292</td>\n      <td>3.850147</td>\n      <td>3.737670</td>\n      <td>3.988984</td>\n      <td>3.258096</td>\n      <td>3.891820</td>\n      <td>3.970292</td>\n      <td>3.610918</td>\n      <td>3.871201</td>\n      <td>3.688879</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 512 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 525
    }
   ],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             24577        24592        16401        8224         36     \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000   \nmean      0.078019     0.000257     0.029228     0.000257     0.002310   \nstd       0.241816     0.013340     0.154096     0.013340     0.039960   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     0.000000     0.000000     0.000000   \nmax       3.332205     0.693147     3.295837     0.693147     0.693147   \n\n             16421        40           16433        16439        8248   ...  \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000  ...   \nmean      0.000257     0.046294     0.000257     0.000513     0.000407  ...   \nstd       0.013340     0.204300     0.013340     0.018862     0.021143  ...   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \nmax       0.693147     1.791759     0.693147     0.693147     1.098612  ...   \n\n             16314        24527        32722        16342        16343  \\\ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000   \nmean      0.000257     0.036518     0.000513     0.000513     0.000513   \nstd       0.013340     0.159245     0.018862     0.018862     0.018862   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     0.000000     0.000000     0.000000   \nmax       0.693147     1.609438     0.693147     0.693147     0.693147   \n\n             8157         16351        8164         8165         16361  \ncount  2700.000000  2700.000000  2700.000000  2700.000000  2700.000000  \nmean      0.000513     0.001027     0.000257     0.000257     0.103054  \nstd       0.018862     0.026664     0.013340     0.013340     0.296921  \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n75%       0.000000     0.000000     0.000000     0.000000     0.000000  \nmax       0.693147     0.693147     0.693147     0.693147     2.079442  \n\n[8 rows x 1425 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>24577</th>\n      <th>24592</th>\n      <th>16401</th>\n      <th>8224</th>\n      <th>36</th>\n      <th>16421</th>\n      <th>40</th>\n      <th>16433</th>\n      <th>16439</th>\n      <th>8248</th>\n      <th>...</th>\n      <th>16314</th>\n      <th>24527</th>\n      <th>32722</th>\n      <th>16342</th>\n      <th>16343</th>\n      <th>8157</th>\n      <th>16351</th>\n      <th>8164</th>\n      <th>8165</th>\n      <th>16361</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>...</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n      <td>2700.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.078019</td>\n      <td>0.000257</td>\n      <td>0.029228</td>\n      <td>0.000257</td>\n      <td>0.002310</td>\n      <td>0.000257</td>\n      <td>0.046294</td>\n      <td>0.000257</td>\n      <td>0.000513</td>\n      <td>0.000407</td>\n      <td>...</td>\n      <td>0.000257</td>\n      <td>0.036518</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.001027</td>\n      <td>0.000257</td>\n      <td>0.000257</td>\n      <td>0.103054</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.241816</td>\n      <td>0.013340</td>\n      <td>0.154096</td>\n      <td>0.013340</td>\n      <td>0.039960</td>\n      <td>0.013340</td>\n      <td>0.204300</td>\n      <td>0.013340</td>\n      <td>0.018862</td>\n      <td>0.021143</td>\n      <td>...</td>\n      <td>0.013340</td>\n      <td>0.159245</td>\n      <td>0.018862</td>\n      <td>0.018862</td>\n      <td>0.018862</td>\n      <td>0.018862</td>\n      <td>0.026664</td>\n      <td>0.013340</td>\n      <td>0.013340</td>\n      <td>0.296921</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.332205</td>\n      <td>0.693147</td>\n      <td>3.295837</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>1.791759</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>1.098612</td>\n      <td>...</td>\n      <td>0.693147</td>\n      <td>1.609438</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>0.693147</td>\n      <td>2.079442</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 1425 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 526
    }
   ],
   "source": [
    "predictor.describe()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595302047524",
   "display_name": "Python 3.8.3 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}